{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "beta= 10**20\n",
    "\n",
    "def MKP1(x):\n",
    "    # D = 28  # et 2 contraintes\n",
    "    yyy = np.array([1898, 440, 22507, 270, 14148, 3100, 4650, 30800, 615, 4975, 1160, 4225, 510, 11880, 479, 440, 490, 330, 110, 560, 24355, 2885, 11748, 4550, 750, 3720, 1950, 10500])\n",
    "    ccc = np.array([600, 600])\n",
    "    A = np.array([[45, 0, 85, 150, 65, 95, 30, 0, 170, 0, 40, 25, 20, 0, 0, 25, 0, 0, 25, 0, 165, 0, 85, 0, 0, 0, 0, 100],\n",
    "                  [30, 20, 125, 5, 80, 25, 35, 73, 12, 15, 15, 40, 5, 10, 10, 12, 10, 9, 0, 20, 60, 40, 50, 36, 49, 40, 19, 150]])\n",
    "    z = np.dot(x,yyy)\n",
    "    weights_used = np.dot(A,x)\n",
    "    z += - beta * np.sum(np.maximum(0, weights_used - ccc) )\n",
    "    return - z # au lieu de z cela revient à minimizer -z\n",
    "\n",
    "def MKP2(x):\n",
    "    # D = 28  # et 2 contraintes\n",
    "    yyy = np.array([1898, 440, 22507, 270, 14148, 3100, 4650, 30800, 615, 4975, 1160, 4225, 510, 11880, 479, 440, 490, 330, 110, 560, 24355, 2885, 11748, 4550, 750, 3720, 1950, 10500])\n",
    "    ccc = np.array([500, 500])\n",
    "    A = np.array([[45, 0, 85, 150, 65, 95, 30, 0, 170, 0, 40, 25, 20, 0, 0, 25, 0, 0, 25, 0, 165, 0, 85, 0, 0, 0, 0, 100],\n",
    "              [30, 20, 125, 5, 80, 25, 35, 73, 12, 15, 15, 40, 5, 10, 10, 12, 10, 9, 0, 20, 60, 40, 50, 36, 49, 40, 19, 150]])\n",
    "    z = np.dot(x,yyy)\n",
    "    weights_used = np.dot(A,x)\n",
    "    z += - beta * np.sum(np.maximum(0, weights_used - ccc) )\n",
    "    return - z # au lieu de z cela revient à minimizer -z\n",
    "\n",
    "def MKP3(x):\n",
    "    # D = 28  # et 2 contraintes\n",
    "    yyy = np.array([1898, 440, 22507, 270, 14148, 3100, 4650, 30800, 615, 4975, 1160, 4225, 510, 11880, 479, 440, 490, 330, 110, 560, 24355, 2885, 11748, 4550, 750, 3720, 1950, 10500])\n",
    "    ccc = np.array([300, 300])\n",
    "    A = np.array([[45, 0, 85, 150, 65, 95, 30, 0, 170, 0, 40, 25, 20, 0, 0, 25, 0, 0, 25, 0, 165, 0, 85, 0, 0, 0, 0, 100],\n",
    "                  [30, 20, 125, 5, 80, 25, 35, 73, 12, 15, 15, 40, 5, 10, 10, 12, 10, 9, 0, 20, 60, 40, 50, 36, 49, 40, 19, 150]])\n",
    "    z = np.dot(x,yyy)\n",
    "    weights_used = np.dot(A,x)\n",
    "    z += - beta * np.sum(np.maximum(0, weights_used - ccc) )\n",
    "    return - z # au lieu de z cela revient à minimizer -z\n",
    "\n",
    "def MKP4(x):\n",
    "    # D = 28  # et 2 contraintes\n",
    "    yyy = np.array([1898, 440, 22507, 270, 14148, 3100, 4650, 30800, 615, 4975, 1160, 4225, 510, 11880, 479, 440, 490, 330, 110, 560, 24355, 2885, 11748, 4550, 750, 3720, 1950, 10500])\n",
    "    ccc = np.array([300, 600])\n",
    "    A = np.array([[45, 0, 85, 150, 65, 95, 30, 0, 170, 0, 40, 25, 20, 0, 0, 25, 0, 0, 25, 0, 165, 0, 85, 0, 0, 0, 0, 100],\n",
    "                  [30, 20, 125, 5, 80, 25, 35, 73, 12, 15, 15, 40, 5, 10, 10, 12, 10, 9, 0, 20, 60, 40, 50, 36, 49, 40, 19, 150]])\n",
    "    z = np.dot(x,yyy)\n",
    "    weights_used = np.dot(A,x)\n",
    "    z += - beta * np.sum(np.maximum(0, weights_used - ccc) )\n",
    "    return - z # au lieu de z cela revient à minimizer -z\n",
    "\n",
    "def MKP5(x):\n",
    "    # D = 28  # et 2 contraintes\n",
    "    yyy = np.array([1898, 440, 22507, 270, 14148, 3100, 4650, 30800, 615, 4975, 1160, 4225, 510, 11880, 479, 440, 490, 330, 110, 560, 24355, 2885, 11748, 4550, 750, 3720, 1950, 10500])\n",
    "    ccc = np.array([600, 300])\n",
    "    A = np.array([[45, 0, 85, 150, 65, 95, 30, 0, 170, 0, 40, 25, 20, 0, 0, 25, 0, 0, 25, 0, 165, 0, 85, 0, 0, 0, 0, 100],\n",
    "                  [30, 20, 125, 5, 80, 25, 35, 73, 12, 15, 15, 40, 5, 10, 10, 12, 10, 9, 0, 20, 60, 40, 50, 36, 49, 40, 19, 150]])\n",
    "    z = np.dot(x,yyy)\n",
    "    weights_used = np.dot(A,x)\n",
    "    z += - beta * np.sum(np.maximum(0, weights_used - ccc) )\n",
    "    return - z # au lieu de z cela revient à minimizer -z\n",
    "\n",
    "def MKP6(x):\n",
    "    # D = 28  # et 2 contraintes\n",
    "    yyy = np.array([1898, 440, 22507, 270, 14148, 3100, 4650, 30800, 615, 4975, 1160, 4225, 510, 11880, 479, 440, 490, 330, 110, 560, 24355, 2885, 11748, 4550, 750, 3720, 1950, 10500])\n",
    "    ccc = np.array([562, 497])\n",
    "    A = np.array([[45, 0, 85, 150, 65, 95, 30, 0, 170, 0, 40, 25, 20, 0, 0, 25, 0, 0, 25, 0, 165, 0, 85, 0, 0, 0, 0, 100],\n",
    "                  [30, 20, 125, 5, 80, 25, 35, 73, 12, 15, 15, 40, 5, 10, 10, 12, 10, 9, 0, 20, 60, 40, 50, 36, 49, 40, 19, 150]])\n",
    "    z = np.dot(x,yyy)\n",
    "    weights_used = np.dot(A,x)\n",
    "    z += - beta * np.sum(np.maximum(0, weights_used - ccc) )\n",
    "    return - z # au lieu de z cela revient à minimizer -z\n",
    "\n",
    "def MKP7(x):\n",
    "    # D = 105  # et 2 contraintes\n",
    "    yyy = np.array([41850, 38261, 23800, 21697, 7074, 5587, 5560, 5500, 3450, 2391, 761, 460, 367, 24785, 47910, 30250, 107200, 4235, 9835, 9262, 15000, 6399, 6155, 10874, 37100, 27040, 4117, 32240, 1600, 4500, 70610, 6570, 15290, 23840, 16500, 7010, 16020, 8000, 31026, 2568, 2365, 4350, 1972, 4975, 29400, 7471, 2700, 3840, 22400, 3575, 13500, 1125, 11950, 12753, 10568, 15600, 20652, 13150, 2900, 1790, 4970, 5770, 8180, 2450, 7140, 12470, 6010, 16000, 11100, 11093, 4685, 2590, 11500, 5820, 2842, 5000, 3300, 2800, 5420, 900, 13300, 8450, 5300, 750, 1435, 2100, 7215, 2605, 2422, 5500, 8550, 2700, 540, 2550, 2450, 725, 445, 700, 1720, 2675, 220, 300, 405, 150, 70])\n",
    "    ccc = np.array([3000, 3000])\n",
    "    A = np.array([\n",
    "        [75, 40, 365, 95, 25, 17, 125, 20, 22, 84, 75, 50, 15, 0, 0, 12, 0, 10, 0, 50, 0, 0, 10, 0, 0, 50, 60, 150, 0, 0, 75, 0, 102, 0, 0, 40, 60, 0, 165, 0, 0, 0, 45, 0, 0, 0, 25, 0, 150, 0, 0, 0, 158, 0, 85, 95, 0, 89, 20, 0, 0, 0, 0, 0, 0, 80, 0, 110, 0, 15, 0, 60, 5, 135, 0, 0, 25, 0, 300, 35, 100, 0, 0, 25, 0, 0, 225, 25, 0, 0, 0, 0, 0, 0, 0, 5, 0, 60, 0, 100, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 10, 10, 50, 2, 5, 5, 10, 5, 6, 11, 41, 30, 5, 40, 2, 6, 100, 10, 25, 39, 30, 13, 30, 15, 60, 5, 5, 10, 5, 15, 91, 24, 10, 15, 90, 15, 60, 5, 55, 60, 50, 75, 100, 65, 15, 10, 30, 35, 50, 15, 45, 80, 40, 110, 80, 80, 36, 20, 90, 50, 25, 50, 35, 30, 60, 10, 150, 110, 70, 10, 20, 30, 104, 40, 40, 94, 150, 50, 10, 50, 50, 16, 10, 20, 50, 90, 10, 15, 39, 20, 20]])\n",
    "    z = np.dot(x,yyy)\n",
    "    weights_used = np.dot(A,x)\n",
    "    z += - beta * np.sum(np.maximum(0, weights_used - ccc) )\n",
    "    return - z # au lieu de z cela revient à minimizer -z\n",
    "\n",
    "def MKP8(x):\n",
    "    #D = 105  # et 2 contraintes\n",
    "    yyy = np.array([41850, 38261, 23800, 21697, 7074, 5587, 5560, 5500, 3450, 2391, 761, 460, 367, 24785, 47910, 30250, 107200, 4235, 9835, 9262, 15000, 6399, 6155, 10874, 37100, 27040, 4117, 32240, 1600, 4500, 70610, 6570, 15290, 23840, 16500, 7010, 16020, 8000, 31026, 2568, 2365, 4350, 1972, 4975, 29400, 7471, 2700, 3840, 22400, 3575, 13500, 1125, 11950, 12753, 10568, 15600, 20652, 13150, 2900, 1790, 4970, 5770, 8180, 2450, 7140, 12470, 6010, 16000, 11100, 11093, 4685, 2590, 11500, 5820, 2842, 5000, 3300, 2800, 5420, 900, 13300, 8450, 5300, 750, 1435, 2100, 7215, 2605, 2422, 5500, 8550, 2700, 540, 2550, 2450, 725, 445, 700, 1720, 2675, 220, 300, 405, 150, 70]) \n",
    "    ccc = np.array([500, 500])\n",
    "    A = np.array([\n",
    "        [75, 40, 365, 95, 25, 17, 125, 20, 22, 84, 75, 50, 15, 0, 0, 12, 0, 10, 0, 50, 0, 0, 10, 0, 0, 50, 60, 150, 0, 0, 75, 0, 102, 0, 0, 40, 60, 0, 165, 0, 0, 0, 45, 0, 0, 0, 25, 0, 150, 0, 0, 0, 158, 0, 85, 95, 0, 89, 20, 0, 0, 0, 0, 0, 0, 80, 0, 110, 0, 15, 0, 60, 5, 135, 0, 0, 25, 0, 300, 35, 100, 0, 0, 25, 0, 0, 225, 25, 0, 0, 0, 0, 0, 0, 0, 5, 0, 60, 0, 100, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 10, 10, 50, 2, 5, 5, 10, 5, 6, 11, 41, 30, 5, 40, 2, 6, 100, 10, 25, 39, 30, 13, 30, 15, 60, 5, 5, 10, 5, 15, 91, 24, 10, 15, 90, 15, 60, 5, 55, 60, 50, 75, 100, 65, 15, 10, 30, 35, 50, 15, 45, 80, 40, 110, 80, 80, 36, 20, 90, 50, 25, 50, 35, 30, 60, 10, 150, 110, 70, 10, 20, 30, 104, 40, 40, 94, 150, 50, 10, 50, 50, 16, 10, 20, 50, 90, 10, 15, 39, 20, 20]])\n",
    "    z = np.dot(x,yyy)\n",
    "    weights_used = np.dot(A,x)\n",
    "    z += - beta * np.sum(np.maximum(0, weights_used - ccc) )\n",
    "    return - z # au lieu de z cela revient à minimizer -z    \n",
    "\n",
    "def MKP9(x):\n",
    "    # D = 60  # et 30 contraintes\n",
    "    yyy = np.array([2, 77, 6, 67, 930, 3, 6, 270, 33, 13, 110, 21, 56, 974, 47, 734, 238, 75, 200, 51, 47, 63, 7, 6, 468, 72, 95, 82, 91, 83, 27, 13, 6, 76, 55, 72, 300, 6, 65, 39, 63, 61, 52, 85, 29, 640, 558, 53, 47, 25, 3, 6, 568, 6, 2, 780, 69, 31, 774, 22])  # 60 objets\n",
    "    ccc = np.array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4000])  # 30 contraintes\n",
    "    A = np.array([\n",
    "        [47, 774, 76, 56, 59, 22, 42, 1, 21, 760, 818, 62, 42, 36, 785, 29, 662, 49, 608, 116, 834, 57, 42, 39, 994, 690, 27, 524, 23, 96, 667, 490, 805, 46, 19, 26, 97, 71, 699, 465, 53, 26, 123, 20, 25, 450, 22, 979, 75, 96, 27, 41, 21, 81, 15, 76, 97, 646, 898, 37],\n",
    "        [73, 67, 27, 99, 35, 794, 53, 378, 234, 32, 792, 97, 64, 19, 435, 712, 837, 22, 504, 332, 13, 65, 86, 29, 894, 266, 75, 16, 86, 91, 67, 445, 118, 73, 97, 370, 88, 85, 165, 268, 758, 21, 255, 81, 5, 774, 39, 377, 18, 370, 96, 61, 57, 23, 13, 164, 908, 834, 960, 87],\n",
    "        [36, 42, 56, 96, 438, 49, 57, 16, 978, 9, 644, 584, 82, 550, 283, 340, 596, 788, 33, 350, 55, 59, 348, 66, 468, 983, 6, 33, 42, 96, 464, 175, 33, 97, 15, 22, 9, 554, 358, 587, 71, 23, 931, 931, 94, 798, 73, 873, 22, 39, 71, 864, 59, 82, 16, 444, 37, 475, 65, 5],\n",
    "        [47, 114, 26, 668, 82, 43, 55, 55, 56, 27, 716, 7, 77, 26, 950, 320, 350, 95, 714, 789, 430, 97, 590, 32, 69, 264, 19, 51, 97, 33, 571, 388, 602, 140, 15, 85, 42, 66, 778, 936, 61, 23, 449, 973, 828, 33, 53, 297, 75, 3, 54, 27, 918, 11, 620, 13, 28, 80, 79, 3],\n",
    "        [61, 720, 7, 31, 22, 82, 688, 19, 82, 654, 809, 99, 81, 97, 830, 826, 775, 72, 9, 719, 740, 860, 72, 30, 82, 112, 66, 638, 150, 13, 586, 590, 519, 2, 320, 13, 964, 754, 70, 241, 72, 12, 996, 868, 36, 91, 79, 221, 49, 690, 23, 18, 748, 408, 688, 97, 85, 777, 294, 17],\n",
    "        [698, 53, 290, 3, 62, 37, 704, 810, 42, 17, 983, 11, 45, 56, 234, 389, 712, 664, 59, 15, 22, 91, 57, 784, 75, 719, 294, 978, 75, 86, 105, 227, 760, 2, 190, 3, 71, 32, 210, 678, 41, 93, 47, 581, 37, 977, 62, 503, 32, 85, 31, 36, 30, 328, 74, 31, 56, 891, 62, 97],\n",
    "        [71, 37, 978, 93, 9, 23, 47, 71, 744, 9, 619, 32, 214, 31, 796, 103, 593, 16, 468, 700, 884, 67, 36, 3, 93, 71, 734, 504, 81, 53, 509, 114, 293, 31, 75, 59, 99, 11, 67, 306, 96, 218, 845, 303, 3, 319, 86, 724, 22, 838, 82, 5, 330, 58, 55, 66, 53, 916, 89, 56],\n",
    "        [33, 27, 13, 57, 6, 87, 21, 12, 15, 290, 206, 420, 32, 880, 854, 417, 770, 4, 12, 952, 604, 13, 96, 910, 34, 460, 76, 16, 140, 100, 876, 622, 559, 39, 640, 59, 6, 244, 232, 513, 644, 7, 813, 624, 990, 274, 808, 372, 2, 694, 804, 39, 5, 644, 914, 484, 1, 8, 43, 92],\n",
    "        [16, 36, 538, 210, 844, 520, 33, 73, 100, 284, 650, 85, 894, 2, 206, 637, 324, 318, 7, 566, 46, 818, 92, 65, 520, 721, 90, 53, 174, 43, 320, 812, 382, 16, 878, 678, 29, 92, 755, 827, 27, 218, 143, 12, 57, 480, 154, 944, 7, 730, 12, 65, 67, 39, 390, 32, 39, 318, 47, 86],\n",
    "        [45, 51, 59, 21, 53, 43, 25, 7, 42, 27, 310, 45, 72, 53, 798, 304, 354, 79, 45, 44, 52, 76, 45, 26, 27, 968, 86, 16, 62, 85, 790, 208, 390, 36, 62, 83, 93, 16, 574, 150, 99, 7, 920, 860, 12, 404, 31, 560, 37, 32, 9, 62, 7, 43, 17, 77, 73, 368, 66, 82],\n",
    "        [11, 51, 97, 26, 83, 426, 92, 39, 66, 2, 23, 93, 85, 660, 85, 774, 77, 77, 927, 868, 7, 554, 760, 104, 48, 202, 45, 75, 51, 55, 716, 752, 37, 95, 267, 91, 5, 956, 444, 529, 96, 99, 17, 99, 62, 7, 394, 580, 604, 89, 678, 476, 97, 234, 1, 608, 19, 69, 676, 51],\n",
    "        [410, 89, 414, 81, 130, 491, 6, 238, 79, 43, 5, 288, 910, 204, 948, 19, 644, 21, 295, 11, 6, 595, 904, 67, 51, 703, 430, 95, 408, 89, 11, 495, 844, 13, 417, 570, 9, 429, 16, 939, 430, 270, 49, 72, 65, 66, 338, 994, 167, 76, 47, 211, 87, 39, 1, 570, 85, 134, 967, 12],\n",
    "        [553, 63, 35, 63, 98, 402, 664, 85, 458, 834, 3, 62, 508, 7, 1, 72, 88, 45, 496, 43, 750, 222, 96, 31, 278, 184, 36, 7, 210, 55, 653, 51, 35, 37, 393, 2, 49, 884, 418, 379, 75, 338, 51, 21, 29, 95, 790, 846, 720, 71, 728, 930, 95, 1, 910, 5, 804, 5, 284, 128],\n",
    "        [423, 6, 58, 36, 37, 321, 22, 26, 16, 27, 218, 530, 93, 55, 89, 71, 828, 75, 628, 67, 66, 622, 440, 91, 73, 790, 710, 59, 83, 968, 129, 632, 170, 67, 613, 608, 43, 71, 730, 910, 36, 92, 950, 138, 23, 95, 460, 62, 189, 73, 65, 943, 62, 554, 46, 318, 13, 540, 90, 53],\n",
    "        [967, 654, 46, 69, 26, 769, 82, 89, 15, 87, 46, 59, 22, 840, 66, 35, 684, 57, 254, 230, 21, 586, 51, 19, 984, 156, 23, 748, 760, 65, 339, 892, 13, 13, 327, 65, 35, 246, 71, 178, 83, 3, 34, 624, 788, 200, 980, 882, 343, 550, 708, 542, 53, 72, 86, 51, 700, 524, 577, 948],\n",
    "        [132, 900, 72, 51, 91, 150, 22, 110, 154, 148, 99, 75, 21, 544, 110, 11, 52, 840, 201, 2, 6, 663, 22, 20, 89, 10, 93, 964, 924, 73, 501, 398, 3, 2, 279, 5, 288, 80, 91, 132, 620, 628, 57, 79, 2, 874, 36, 497, 846, 22, 350, 866, 57, 86, 83, 178, 968, 52, 399, 628],\n",
    "        [869, 26, 710, 37, 81, 89, 6, 82, 82, 56, 96, 66, 46, 13, 934, 49, 394, 72, 194, 408, 5, 541, 88, 93, 36, 398, 508, 89, 66, 16, 71, 466, 7, 95, 464, 41, 69, 130, 488, 695, 82, 39, 95, 53, 37, 200, 87, 56, 268, 71, 304, 855, 22, 564, 47, 26, 26, 370, 569, 2],\n",
    "        [494, 2, 25, 61, 674, 638, 61, 59, 62, 690, 630, 86, 198, 24, 15, 650, 75, 25, 571, 338, 268, 958, 95, 898, 56, 585, 99, 83, 21, 600, 462, 940, 96, 464, 228, 93, 72, 734, 89, 287, 174, 62, 51, 73, 42, 838, 82, 515, 232, 91, 25, 47, 12, 56, 65, 734, 70, 48, 209, 71],\n",
    "        [267, 290, 31, 844, 12, 570, 13, 69, 65, 848, 72, 780, 27, 96, 97, 17, 69, 274, 616, 36, 554, 236, 47, 7, 47, 134, 76, 62, 824, 55, 374, 471, 478, 504, 496, 754, 604, 923, 330, 22, 97, 6, 2, 16, 14, 958, 53, 480, 482, 93, 57, 641, 72, 75, 51, 96, 83, 47, 403, 32],\n",
    "        [624, 7, 96, 45, 97, 148, 91, 3, 69, 26, 22, 45, 42, 2, 75, 76, 96, 67, 688, 2, 2, 224, 83, 69, 41, 660, 81, 89, 93, 27, 214, 458, 66, 72, 384, 59, 76, 538, 15, 840, 65, 63, 77, 33, 92, 32, 35, 832, 970, 49, 13, 8, 77, 75, 51, 95, 56, 63, 578, 47],\n",
    "        [33, 62, 928, 292, 2, 340, 278, 911, 818, 770, 464, 53, 888, 55, 76, 31, 389, 40, 864, 36, 35, 37, 69, 95, 22, 648, 334, 14, 198, 42, 73, 594, 95, 32, 814, 45, 45, 515, 634, 254, 42, 29, 15, 83, 55, 176, 35, 46, 60, 296, 262, 598, 67, 644, 80, 999, 3, 727, 79, 374],\n",
    "        [19, 780, 400, 588, 37, 86, 23, 583, 518, 42, 56, 1, 108, 83, 43, 720, 570, 81, 674, 25, 96, 218, 6, 69, 107, 534, 158, 56, 5, 938, 9, 938, 274, 76, 298, 9, 518, 571, 47, 175, 63, 93, 49, 94, 42, 26, 79, 50, 718, 926, 419, 810, 23, 363, 519, 339, 86, 751, 7, 86],\n",
    "        [47, 75, 55, 554, 3, 800, 6, 13, 85, 65, 99, 45, 69, 73, 864, 95, 199, 924, 19, 948, 214, 3, 718, 56, 278, 1, 363, 86, 1, 22, 56, 114, 13, 53, 56, 19, 82, 88, 99, 543, 674, 704, 418, 670, 554, 282, 5, 67, 63, 466, 491, 49, 67, 154, 956, 911, 77, 635, 2, 49],\n",
    "        [53, 12, 79, 481, 218, 26, 624, 954, 13, 580, 130, 608, 3, 37, 91, 78, 743, 1, 950, 45, 41, 718, 36, 30, 534, 418, 452, 359, 759, 88, 29, 499, 55, 974, 93, 56, 108, 257, 93, 171, 13, 92, 63, 714, 9, 84, 890, 16, 930, 967, 748, 5, 7, 6, 327, 894, 33, 629, 448, 21],\n",
    "        [9, 19, 7, 535, 75, 3, 27, 928, 21, 7, 864, 27, 73, 61, 25, 75, 876, 16, 92, 22, 248, 11, 86, 944, 872, 996, 252, 2, 800, 334, 93, 107, 254, 441, 930, 744, 97, 177, 498, 931, 694, 800, 9, 36, 6, 539, 35, 79, 130, 860, 710, 7, 630, 475, 903, 552, 2, 45, 97, 974],\n",
    "        [17, 36, 77, 843, 328, 22, 76, 368, 39, 71, 35, 850, 96, 93, 87, 56, 972, 96, 594, 864, 344, 76, 17, 17, 576, 629, 780, 640, 56, 65, 43, 196, 520, 86, 92, 31, 6, 593, 174, 569, 89, 718, 83, 8, 790, 285, 780, 62, 378, 313, 519, 2, 85, 845, 931, 731, 42, 365, 32, 33],\n",
    "        [65, 59, 2, 671, 26, 364, 854, 526, 570, 630, 33, 654, 95, 41, 42, 27, 584, 17, 724, 59, 42, 26, 918, 6, 242, 356, 75, 644, 818, 168, 964, 12, 97, 178, 634, 21, 3, 586, 47, 382, 804, 89, 194, 21, 610, 168, 79, 96, 87, 266, 482, 46, 96, 969, 629, 128, 924, 812, 19, 2],\n",
    "        [468, 13, 9, 120, 73, 7, 92, 99, 93, 418, 224, 22, 7, 29, 57, 33, 949, 65, 92, 898, 200, 57, 12, 31, 296, 185, 272, 91, 77, 37, 734, 911, 27, 310, 59, 33, 87, 872, 73, 79, 920, 85, 59, 72, 888, 49, 12, 79, 538, 947, 462, 444, 828, 935, 518, 894, 13, 591, 22, 920],\n",
    "        [23, 93, 87, 490, 32, 63, 870, 393, 52, 23, 63, 634, 39, 83, 12, 72, 131, 69, 984, 87, 86, 99, 52, 110, 183, 704, 232, 674, 384, 47, 804, 99, 83, 81, 174, 99, 77, 708, 7, 623, 114, 1, 750, 49, 284, 492, 11, 61, 6, 449, 429, 52, 62, 482, 826, 147, 338, 911, 30, 984],\n",
    "        [35, 55, 21, 264, 5, 35, 92, 128, 65, 27, 9, 52, 66, 51, 7, 47, 670, 83, 76, 7, 79, 37, 2, 46, 480, 608, 990, 53, 47, 19, 35, 518, 71, 59, 32, 87, 96, 240, 52, 310, 86, 73, 52, 31, 83, 544, 16, 15, 21, 774, 224, 7, 83, 680, 554, 310, 96, 844, 29, 61]\n",
    "    ])\n",
    "    z = np.dot(x,yyy)\n",
    "    weights_used = np.dot(A,x)\n",
    "    z += - beta * np.sum(np.maximum(0, weights_used - ccc) )\n",
    "    return - z # au lieu de z cela revient à minimizer -z\n",
    "\n",
    "def MKP10(x):\n",
    "    # D = 60  # et 30 contraintes\n",
    "    yyy = np.array([2, 77, 6, 67, 930, 3, 6, 270, 33, 13, 110, 21, 56, 974, 47, 734, 238, 75, 200, 51, 47, 63, 7, 6, 468, 72, 95, 82, 91, 83, 27, 13, 6, 76, 55, 72, 300, 6, 65, 39, 63, 61, 52, 85, 29, 640, 558, 53, 47, 25, 3, 6, 568, 6, 2, 780, 69, 31, 774, 22])\n",
    "    ccc = np.array([10000] * 27 + [7000] + [10000] * 2) \n",
    "    A = np.array([\n",
    "        [47, 774, 76, 56, 59, 22, 42, 1, 21, 760, 818, 62, 42, 36, 785, 29, 662, 49, 608, 116, 834, 57, 42, 39, 994, 690, 27, 524, 23, 96, 667, 490, 805, 46, 19, 26, 97, 71, 699, 465, 53, 26, 123, 20, 25, 450, 22, 979, 75, 96, 27, 41, 21, 81, 15, 76, 97, 646, 898, 37],\n",
    "        [73, 67, 27, 99, 35, 794, 53, 378, 234, 32, 792, 97, 64, 19, 435, 712, 837, 22, 504, 332, 13, 65, 86, 29, 894, 266, 75, 16, 86, 91, 67, 445, 118, 73, 97, 370, 88, 85, 165, 268, 758, 21, 255, 81, 5, 774, 39, 377, 18, 370, 96, 61, 57, 23, 13, 164, 908, 834, 960, 87],\n",
    "        [36, 42, 56, 96, 438, 49, 57, 16, 978, 9, 644, 584, 82, 550, 283, 340, 596, 788, 33, 350, 55, 59, 348, 66, 468, 983, 6, 33, 42, 96, 464, 175, 33, 97, 15, 22, 9, 554, 358, 587, 71, 23, 931, 931, 94, 798, 73, 873, 22, 39, 71, 864, 59, 82, 16, 444, 37, 475, 65, 5],\n",
    "        [47, 114, 26, 668, 82, 43, 55, 55, 56, 27, 716, 7, 77, 26, 950, 320, 350, 95, 714, 789, 430, 97, 590, 32, 69, 264, 19, 51, 97, 33, 571, 388, 602, 140, 15, 85, 42, 66, 778, 936, 61, 23, 449, 973, 828, 33, 53, 297, 75, 3, 54, 27, 918, 11, 620, 13, 28, 80, 79, 3],\n",
    "        [61, 720, 7, 31, 22, 82, 688, 19, 82, 654, 809, 99, 81, 97, 830, 826, 775, 72, 9, 719, 740, 860, 72, 30, 82, 112, 66, 638, 150, 13, 586, 590, 519, 2, 320, 13, 964, 754, 70, 241, 72, 12, 996, 868, 36, 91, 79, 221, 49, 690, 23, 18, 748, 408, 688, 97, 85, 777, 294, 17],\n",
    "        [698, 53, 290, 3, 62, 37, 704, 810, 42, 17, 983, 11, 45, 56, 234, 389, 712, 664, 59, 15, 22, 91, 57, 784, 75, 719, 294, 978, 75, 86, 105, 227, 760, 2, 190, 3, 71, 32, 210, 678, 41, 93, 47, 581, 37, 977, 62, 503, 32, 85, 31, 36, 30, 328, 74, 31, 56, 891, 62, 97],\n",
    "        [71, 37, 978, 93, 9, 23, 47, 71, 744, 9, 619, 32, 214, 31, 796, 103, 593, 16, 468, 700, 884, 67, 36, 3, 93, 71, 734, 504, 81, 53, 509, 114, 293, 31, 75, 59, 99, 11, 67, 306, 96, 218, 845, 303, 3, 319, 86, 724, 22, 838, 82, 5, 330, 58, 55, 66, 53, 916, 89, 56],\n",
    "        [33, 27, 13, 57, 6, 87, 21, 12, 15, 290, 206, 420, 32, 880, 854, 417, 770, 4, 12, 952, 604, 13, 96, 910, 34, 460, 76, 16, 140, 100, 876, 622, 559, 39, 640, 59, 6, 244, 232, 513, 644, 7, 813, 624, 990, 274, 808, 372, 2, 694, 804, 39, 5, 644, 914, 484, 1, 8, 43, 92],\n",
    "        [16, 36, 538, 210, 844, 520, 33, 73, 100, 284, 650, 85, 894, 2, 206, 637, 324, 318, 7, 566, 46, 818, 92, 65, 520, 721, 90, 53, 174, 43, 320, 812, 382, 16, 878, 678, 29, 92, 755, 827, 27, 218, 143, 12, 57, 480, 154, 944, 7, 730, 12, 65, 67, 39, 390, 32, 39, 318, 47, 86],\n",
    "        [45, 51, 59, 21, 53, 43, 25, 7, 42, 27, 310, 45, 72, 53, 798, 304, 354, 79, 45, 44, 52, 76, 45, 26, 27, 968, 86, 16, 62, 85, 790, 208, 390, 36, 62, 83, 93, 16, 574, 150, 99, 7, 920, 860, 12, 404, 31, 560, 37, 32, 9, 62, 7, 43, 17, 77, 73, 368, 66, 82],\n",
    "        [11, 51, 97, 26, 83, 426, 92, 39, 66, 2, 23, 93, 85, 660, 85, 774, 77, 77, 927, 868, 7, 554, 760, 104, 48, 202, 45, 75, 51, 55, 716, 752, 37, 95, 267, 91, 5, 956, 444, 529, 96, 99, 17, 99, 62, 7, 394, 580, 604, 89, 678, 476, 97, 234, 1, 608, 19, 69, 676, 51],\n",
    "        [410, 89, 414, 81, 130, 491, 6, 238, 79, 43, 5, 288, 910, 204, 948, 19, 644, 21, 295, 11, 6, 595, 904, 67, 51, 703, 430, 95, 408, 89, 11, 495, 844, 13, 417, 570, 9, 429, 16, 939, 430, 270, 49, 72, 65, 66, 338, 994, 167, 76, 47, 211, 87, 39, 1, 570, 85, 134, 967, 12],\n",
    "        [553, 63, 35, 63, 98, 402, 664, 85, 458, 834, 3, 62, 508, 7, 1, 72, 88, 45, 496, 43, 750, 222, 96, 31, 278, 184, 36, 7, 210, 55, 653, 51, 35, 37, 393, 2, 49, 884, 418, 379, 75, 338, 51, 21, 29, 95, 790, 846, 720, 71, 728, 930, 95, 1, 910, 5, 804, 5, 284, 128],\n",
    "        [423, 6, 58, 36, 37, 321, 22, 26, 16, 27, 218, 530, 93, 55, 89, 71, 828, 75, 628, 67, 66, 622, 440, 91, 73, 790, 710, 59, 83, 968, 129, 632, 170, 67, 613, 608, 43, 71, 730, 910, 36, 92, 950, 138, 23, 95, 460, 62, 189, 73, 65, 943, 62, 554, 46, 318, 13, 540, 90, 53],\n",
    "        [967, 654, 46, 69, 26, 769, 82, 89, 15, 87, 46, 59, 22, 840, 66, 35, 684, 57, 254, 230, 21, 586, 51, 19, 984, 156, 23, 748, 760, 65, 339, 892, 13, 13, 327, 65, 35, 246, 71, 178, 83, 3, 34, 624, 788, 200, 980, 882, 343, 550, 708, 542, 53, 72, 86, 51, 700, 524, 577, 948],\n",
    "        [132, 900, 72, 51, 91, 150, 22, 110, 154, 148, 99, 75, 21, 544, 110, 11, 52, 840, 201, 2, 6, 663, 22, 20, 89, 10, 93, 964, 924, 73, 501, 398, 3, 2, 279, 5, 288, 80, 91, 132, 620, 628, 57, 79, 2, 874, 36, 497, 846, 22, 350, 866, 57, 86, 83, 178, 968, 52, 399, 628],\n",
    "        [869, 26, 710, 37, 81, 89, 6, 82, 82, 56, 96, 66, 46, 13, 934, 49, 394, 72, 194, 408, 5, 541, 88, 93, 36, 398, 508, 89, 66, 16, 71, 466, 7, 95, 464, 41, 69, 130, 488, 695, 82, 39, 95, 53, 37, 200, 87, 56, 268, 71, 304, 855, 22, 564, 47, 26, 26, 370, 569, 2],\n",
    "        [494, 2, 25, 61, 674, 638, 61, 59, 62, 690, 630, 86, 198, 24, 15, 650, 75, 25, 571, 338, 268, 958, 95, 898, 56, 585, 99, 83, 21, 600, 462, 940, 96, 464, 228, 93, 72, 734, 89, 287, 174, 62, 51, 73, 42, 838, 82, 515, 232, 91, 25, 47, 12, 56, 65, 734, 70, 48, 209, 71],\n",
    "        [267, 290, 31, 844, 12, 570, 13, 69, 65, 848, 72, 780, 27, 96, 97, 17, 69, 274, 616, 36, 554, 236, 47, 7, 47, 134, 76, 62, 824, 55, 374, 471, 478, 504, 496, 754, 604, 923, 330, 22, 97, 6, 2, 16, 14, 958, 53, 480, 482, 93, 57, 641, 72, 75, 51, 96, 83, 47, 403, 32],\n",
    "        [624, 7, 96, 45, 97, 148, 91, 3, 69, 26, 22, 45, 42, 2, 75, 76, 96, 67, 688, 2, 2, 224, 83, 69, 41, 660, 81, 89, 93, 27, 214, 458, 66, 72, 384, 59, 76, 538, 15, 840, 65, 63, 77, 33, 92, 32, 35, 832, 970, 49, 13, 8, 77, 75, 51, 95, 56, 63, 578, 47],\n",
    "        [33, 62, 928, 292, 2, 340, 278, 911, 818, 770, 464, 53, 888, 55, 76, 31, 389, 40, 864, 36, 35, 37, 69, 95, 22, 648, 334, 14, 198, 42, 73, 594, 95, 32, 814, 45, 45, 515, 634, 254, 42, 29, 15, 83, 55, 176, 35, 46, 60, 296, 262, 598, 67, 644, 80, 999, 3, 727, 79, 374],\n",
    "        [19, 780, 400, 588, 37, 86, 23, 583, 518, 42, 56, 1, 108, 83, 43, 720, 570, 81, 674, 25, 96, 218, 6, 69, 107, 534, 158, 56, 5, 938, 9, 938, 274, 76, 298, 9, 518, 571, 47, 175, 63, 93, 49, 94, 42, 26, 79, 50, 718, 926, 419, 810, 23, 363, 519, 339, 86, 751, 7, 86],\n",
    "        [47, 75, 55, 554, 3, 800, 6, 13, 85, 65, 99, 45, 69, 73, 864, 95, 199, 924, 19, 948, 214, 3, 718, 56, 278, 1, 363, 86, 1, 22, 56, 114, 13, 53, 56, 19, 82, 88, 99, 543, 674, 704, 418, 670, 554, 282, 5, 67, 63, 466, 491, 49, 67, 154, 956, 911, 77, 635, 2, 49],\n",
    "        [53, 12, 79, 481, 218, 26, 624, 954, 13, 580, 130, 608, 3, 37, 91, 78, 743, 1, 950, 45, 41, 718, 36, 30, 534, 418, 452, 359, 759, 88, 29, 499, 55, 974, 93, 56, 108, 257, 93, 171, 13, 92, 63, 714, 9, 84, 890, 16, 930, 967, 748, 5, 7, 6, 327, 894, 33, 629, 448, 21],\n",
    "        [9, 19, 7, 535, 75, 3, 27, 928, 21, 7, 864, 27, 73, 61, 25, 75, 876, 16, 92, 22, 248, 11, 86, 944, 872, 996, 252, 2, 800, 334, 93, 107, 254, 441, 930, 744, 97, 177, 498, 931, 694, 800, 9, 36, 6, 539, 35, 79, 130, 860, 710, 7, 630, 475, 903, 552, 2, 45, 97, 974],\n",
    "        [17, 36, 77, 843, 328, 22, 76, 368, 39, 71, 35, 850, 96, 93, 87, 56, 972, 96, 594, 864, 344, 76, 17, 17, 576, 629, 780, 640, 56, 65, 43, 196, 520, 86, 92, 31, 6, 593, 174, 569, 89, 718, 83, 8, 790, 285, 780, 62, 378, 313, 519, 2, 85, 845, 931, 731, 42, 365, 32, 33],\n",
    "        [65, 59, 2, 671, 26, 364, 854, 526, 570, 630, 33, 654, 95, 41, 42, 27, 584, 17, 724, 59, 42, 26, 918, 6, 242, 356, 75, 644, 818, 168, 964, 12, 97, 178, 634, 21, 3, 586, 47, 382, 804, 89, 194, 21, 610, 168, 79, 96, 87, 266, 482, 46, 96, 969, 629, 128, 924, 812, 19, 2],\n",
    "        [468, 13, 9, 120, 73, 7, 92, 99, 93, 418, 224, 22, 7, 29, 57, 33, 949, 65, 92, 898, 200, 57, 12, 31, 296, 185, 272, 91, 77, 37, 734, 911, 27, 310, 59, 33, 87, 872, 73, 79, 920, 85, 59, 72, 888, 49, 12, 79, 538, 947, 462, 444, 828, 935, 518, 894, 13, 591, 22, 920],\n",
    "        [23, 93, 87, 490, 32, 63, 870, 393, 52, 23, 63, 634, 39, 83, 12, 72, 131, 69, 984, 87, 86, 99, 52, 110, 183, 704, 232, 674, 384, 47, 804, 99, 83, 81, 174, 99, 77, 708, 7, 623, 114, 1, 750, 49, 284, 492, 11, 61, 6, 449, 429, 52, 62, 482, 826, 147, 338, 911, 30, 984],\n",
    "        [35, 55, 21, 264, 5, 35, 92, 128, 65, 27, 9, 52, 66, 51, 7, 47, 670, 83, 76, 7, 79, 37, 2, 46, 480, 608, 990, 53, 47, 19, 35, 518, 71, 59, 32, 87, 96, 240, 52, 310, 86, 73, 52, 31, 83, 544, 16, 15, 21, 774, 224, 7, 83, 680, 554, 310, 96, 844, 29, 61]\n",
    "    ])\n",
    "    z = np.dot(x,yyy)\n",
    "    weights_used = np.dot(A,x)\n",
    "    z += - beta * np.sum(np.maximum(0, weights_used - ccc) )\n",
    "    return - z # au lieu de z cela revient à minimizer -z\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class HybridPSOGSA:\n",
    "    def __init__(self, pop_size=30, max_iter=1000):\n",
    "        # PSO parameters - taken from successful BPSO2\n",
    "        self.pop_size = pop_size\n",
    "        self.max_iter = max_iter\n",
    "        self.w_start = 0.9\n",
    "        self.w_end = 0.4\n",
    "        self.c1 = 8.0  # Higher cognitive component from BPSO2\n",
    "        self.c2 = 4.0  # Lower social component from BPSO2\n",
    "        \n",
    "        # GSA parameters - from successful BGSA1\n",
    "        self.G0 = 100\n",
    "        self.alpha = 20\n",
    "        self.force_limit = 100\n",
    "        \n",
    "        # Hybrid balance - emphasize PSO early, GSA later\n",
    "        self.gsa_weight_start = 0.2\n",
    "        self.gsa_weight_end = 0.4\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -6, 6)))\n",
    "    \n",
    "    def evaluate_fitness(self, solution, func):\n",
    "        value = -func(solution)\n",
    "        return value if value > -1e10 else 0\n",
    "    \n",
    "    def repair_solution(self, solution, func):\n",
    "        if self.evaluate_fitness(solution, func) > 0:\n",
    "            return solution\n",
    "            \n",
    "        repaired = solution.copy()\n",
    "        selected = np.where(repaired == 1)[0]\n",
    "        if len(selected) <= 1:\n",
    "            return np.zeros_like(solution)\n",
    "            \n",
    "        np.random.shuffle(selected)\n",
    "        \n",
    "        # Try removing items one by one\n",
    "        for idx in selected:\n",
    "            repaired[idx] = 0\n",
    "            if self.evaluate_fitness(repaired, func) > 0:\n",
    "                return repaired\n",
    "                \n",
    "        return np.zeros_like(solution)\n",
    "    \n",
    "    def calculate_forces(self, positions, fitness, G, iteration):\n",
    "        n_particles, dimension = positions.shape\n",
    "        forces = np.zeros((n_particles, dimension))\n",
    "        \n",
    "        # Normalize fitness for mass calculation\n",
    "        min_fit = np.min(fitness)\n",
    "        max_fit = np.max(fitness)\n",
    "        if max_fit > min_fit:\n",
    "            masses = (fitness - min_fit) / (max_fit - min_fit)\n",
    "        else:\n",
    "            masses = np.ones(len(fitness)) / len(fitness)\n",
    "        masses = masses / np.sum(masses)\n",
    "        \n",
    "        # Adaptive k_best\n",
    "        k_best = max(3, int(self.pop_size * (1 - iteration/self.max_iter)))\n",
    "        best_indices = np.argsort(fitness)[-k_best:]\n",
    "        \n",
    "        for i in range(n_particles):\n",
    "            force = np.zeros(dimension)\n",
    "            for j in best_indices:\n",
    "                if i != j:\n",
    "                    diff = positions[j] - positions[i]\n",
    "                    R = np.sum(diff ** 2) + 1e-10\n",
    "                    magnitude = G * masses[i] * masses[j] / np.sqrt(R)\n",
    "                    magnitude = np.clip(magnitude, -self.force_limit, self.force_limit)\n",
    "                    force += magnitude * diff\n",
    "            forces[i] = force\n",
    "            \n",
    "        return forces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def optimize(self, func, dimension):\n",
    "        # Initialize population with lower density for knapsack\n",
    "        positions = (np.random.random((self.pop_size, dimension)) < 0.2).astype(int)\n",
    "        velocities = np.random.uniform(-4, 4, (self.pop_size, dimension))\n",
    "        \n",
    "        # Repair initial solutions\n",
    "        for i in range(self.pop_size):\n",
    "            positions[i] = self.repair_solution(positions[i], func)\n",
    "        \n",
    "        # Initialize best positions\n",
    "        fitness = np.array([self.evaluate_fitness(p, func) for p in positions])\n",
    "        personal_best_positions = positions.copy()\n",
    "        personal_best_fitness = fitness.copy()\n",
    "        \n",
    "        global_best_idx = np.argmax(fitness)\n",
    "        global_best_position = positions[global_best_idx].copy()\n",
    "        global_best_fitness = fitness[global_best_idx]\n",
    "        \n",
    "        convergence_history = [global_best_fitness]\n",
    "        no_improvement_count = 0\n",
    "        \n",
    "        for t in range(self.max_iter):\n",
    "            # Update control parameters\n",
    "            progress = t / self.max_iter\n",
    "            w = self.w_start - (self.w_start - self.w_end) * progress\n",
    "            gsa_weight = self.gsa_weight_start + (self.gsa_weight_end - self.gsa_weight_start) * progress\n",
    "            G = self.G0 * np.exp(-self.alpha * progress)\n",
    "            \n",
    "            # Update fitness\n",
    "            fitness = np.array([self.evaluate_fitness(p, func) for p in positions])\n",
    "            \n",
    "            # Update personal and global bests\n",
    "            improved = fitness > personal_best_fitness\n",
    "            personal_best_positions[improved] = positions[improved].copy()\n",
    "            personal_best_fitness[improved] = fitness[improved]\n",
    "            \n",
    "            current_best = np.argmax(fitness)\n",
    "            if fitness[current_best] > global_best_fitness:\n",
    "                global_best_position = positions[current_best].copy()\n",
    "                global_best_fitness = fitness[current_best]\n",
    "                no_improvement_count = 0\n",
    "            else:\n",
    "                no_improvement_count += 1\n",
    "            \n",
    "            # Calculate GSA forces\n",
    "            forces = self.calculate_forces(positions, fitness, G, t)\n",
    "            \n",
    "            # PSO velocity components\n",
    "            r1, r2 = np.random.random((2, self.pop_size, dimension))\n",
    "            cognitive = self.c1 * r1 * (personal_best_positions - positions)\n",
    "            social = self.c2 * r2 * (global_best_position - positions)\n",
    "            \n",
    "            # Combine PSO and GSA\n",
    "            velocities = w * velocities + (1 - gsa_weight) * (cognitive + social) + gsa_weight * forces\n",
    "            velocities = np.clip(velocities, -4, 4)\n",
    "            \n",
    "            # Binary position update\n",
    "            positions = (np.random.random((self.pop_size, dimension)) < self.sigmoid(velocities)).astype(int)\n",
    "            \n",
    "            # Add diversity when stuck\n",
    "            if no_improvement_count > 20:\n",
    "                mask = np.random.random(dimension) < 0.1\n",
    "                positions[np.random.randint(self.pop_size)] = mask\n",
    "                no_improvement_count = 0\n",
    "            \n",
    "            # Repair infeasible solutions\n",
    "            for i in range(self.pop_size):\n",
    "                positions[i] = self.repair_solution(positions[i], func)\n",
    "            \n",
    "            convergence_history.append(global_best_fitness)\n",
    "        \n",
    "        return global_best_position, global_best_fitness, convergence_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "def run_experiments(problems, n_runs=30):\n",
    "    results = {}\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    save_dir = f\"hybrid_results_{timestamp}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    convergence_data = {prob: [] for prob in problems}\n",
    "    \n",
    "    for problem_name, (func, dimension) in problems.items():\n",
    "        print(f\"\\nSolving {problem_name}\")\n",
    "        problem_results = []\n",
    "        histories = []\n",
    "        \n",
    "        for run in tqdm(range(n_runs)):\n",
    "            optimizer = HybridPSOGSA(pop_size=30, max_iter=1000)\n",
    "            best_solution, best_fitness, history = optimizer.optimize(func, dimension)\n",
    "            problem_results.append(best_fitness)\n",
    "            histories.append(history)\n",
    "            \n",
    "        results[problem_name] = {\n",
    "            'Best': float(max(problem_results)),\n",
    "            'Mean': float(np.mean(problem_results)),\n",
    "            'StdDev': float(np.std(problem_results))\n",
    "        }\n",
    "        convergence_data[problem_name] = histories\n",
    "    \n",
    "    # Save results\n",
    "    with open(os.path.join(save_dir, 'hybrid_results.json'), 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "        \n",
    "    return results, save_dir, convergence_data\n",
    "\n",
    "def create_convergence_plots(problems, convergence_data, save_dir):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(25, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (problem_name, (func, dim)) in enumerate(problems.items()):\n",
    "        ax = axes[idx]\n",
    "        histories = np.array(convergence_data[problem_name])\n",
    "        \n",
    "        if len(histories) > 0:\n",
    "            # Ensure all sequences have same length\n",
    "            min_len = min(len(h) for h in histories)\n",
    "            histories = np.array([h[:min_len] for h in histories])\n",
    "            \n",
    "            mean_curve = np.mean(histories, axis=0)\n",
    "            std_curve = np.std(histories, axis=0)\n",
    "            \n",
    "            ax.plot(mean_curve, color='blue', label='Mean', linewidth=2.5)\n",
    "            ax.fill_between(range(len(mean_curve)),\n",
    "                          mean_curve - std_curve,\n",
    "                          mean_curve + std_curve,\n",
    "                          color='blue', alpha=0.15)\n",
    "            \n",
    "        ax.set_title(f'{problem_name} Convergence\\n(dim={dim})', fontsize=11, pad=10)\n",
    "        ax.set_xlabel('Iteration', fontsize=10)\n",
    "        ax.set_ylabel('Profit', fontsize=10)\n",
    "        ax.grid(True, linestyle='--', alpha=0.5)\n",
    "        \n",
    "        if ax.get_ylim()[1] > 1e5:\n",
    "            ax.yaxis.set_major_formatter(plt.ScalarFormatter(useMathText=True))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, 'convergence_plots.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hybrid BPSO-GSA experiments...\n",
      "Number of problems: 10\n",
      "Runs per problem: 30\n",
      "Current time: 2024-11-24 01:13:17\n",
      "\n",
      "\n",
      "Solving MKP1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [08:06<00:00, 16.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solving MKP2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [05:27<00:00, 10.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solving MKP3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [06:28<00:00, 12.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solving MKP4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [06:42<00:00, 13.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solving MKP5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [05:58<00:00, 11.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solving MKP6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [05:15<00:00, 10.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solving MKP7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [04:50<00:00,  9.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solving MKP8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [23:11<00:00, 46.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solving MKP9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [33:46<00:00, 67.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solving MKP10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [21:02<00:00, 42.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Summary:\n",
      "--------------------------------------------------\n",
      "\n",
      "MKP1:\n",
      "Best:    141278.00\n",
      "Mean:    141278.00\n",
      "StdDev:  0.00\n",
      "\n",
      "MKP2:\n",
      "Best:    130883.00\n",
      "Mean:    130874.00\n",
      "StdDev:  34.29\n",
      "\n",
      "MKP3:\n",
      "Best:    95677.00\n",
      "Mean:    95677.00\n",
      "StdDev:  0.00\n",
      "\n",
      "MKP4:\n",
      "Best:    119337.00\n",
      "Mean:    119238.20\n",
      "StdDev:  487.87\n",
      "\n",
      "MKP5:\n",
      "Best:    98796.00\n",
      "Mean:    98796.00\n",
      "StdDev:  0.00\n",
      "\n",
      "MKP6:\n",
      "Best:    130623.00\n",
      "Mean:    130519.00\n",
      "StdDev:  172.46\n",
      "\n",
      "MKP7:\n",
      "Best:    1067471.00\n",
      "Mean:    1047452.77\n",
      "StdDev:  8916.45\n",
      "\n",
      "MKP8:\n",
      "Best:    518077.00\n",
      "Mean:    474464.13\n",
      "StdDev:  16085.13\n",
      "\n",
      "MKP9:\n",
      "Best:    7623.00\n",
      "Mean:    7306.73\n",
      "StdDev:  101.98\n",
      "\n",
      "MKP10:\n",
      "Best:    8595.00\n",
      "Mean:    8535.37\n",
      "StdDev:  29.98\n",
      "\n",
      "Total execution time: 120.87 minutes\n",
      "Results saved in: hybrid_results_20241124_011317\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define all test problems\n",
    "    problems = {\n",
    "        'MKP1': (MKP1, 28),\n",
    "        'MKP2': (MKP2, 28),\n",
    "        'MKP3': (MKP3, 28),\n",
    "        'MKP4': (MKP4, 28),\n",
    "        'MKP5': (MKP5, 28),\n",
    "        'MKP6': (MKP6, 28),\n",
    "        'MKP7': (MKP7, 105),\n",
    "        'MKP8': (MKP8, 105),\n",
    "        'MKP9': (MKP9, 60),\n",
    "        'MKP10': (MKP10, 60)\n",
    "    }\n",
    "\n",
    "    print(\"Starting Hybrid BPSO-GSA experiments...\")\n",
    "    print(f\"Number of problems: {len(problems)}\")\n",
    "    print(f\"Runs per problem: 30\")\n",
    "    print(f\"Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        results, save_dir, convergence_data = run_experiments(problems, n_runs=30)\n",
    "        \n",
    "        # Create plots\n",
    "        create_convergence_plots(problems, convergence_data, save_dir)\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(\"\\nResults Summary:\")\n",
    "        print(\"-\" * 50)\n",
    "        for problem, stats in results.items():\n",
    "            print(f\"\\n{problem}:\")\n",
    "            print(f\"Best:    {stats['Best']:.2f}\")\n",
    "            print(f\"Mean:    {stats['Mean']:.2f}\")\n",
    "            print(f\"StdDev:  {stats['StdDev']:.2f}\")\n",
    "        \n",
    "        total_time = (time.time() - start_time) / 60\n",
    "        print(f\"\\nTotal execution time: {total_time:.2f} minutes\")\n",
    "        print(f\"Results saved in: {save_dir}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during execution: {str(e)}\")\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
