{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "beta= 10**20\n",
    "\n",
    "def MKP1(x):\n",
    "    # D = 28  # et 2 contraintes\n",
    "    yyy = np.array([1898, 440, 22507, 270, 14148, 3100, 4650, 30800, 615, 4975, 1160, 4225, 510, 11880, 479, 440, 490, 330, 110, 560, 24355, 2885, 11748, 4550, 750, 3720, 1950, 10500])\n",
    "    ccc = np.array([600, 600])\n",
    "    A = np.array([[45, 0, 85, 150, 65, 95, 30, 0, 170, 0, 40, 25, 20, 0, 0, 25, 0, 0, 25, 0, 165, 0, 85, 0, 0, 0, 0, 100],\n",
    "                  [30, 20, 125, 5, 80, 25, 35, 73, 12, 15, 15, 40, 5, 10, 10, 12, 10, 9, 0, 20, 60, 40, 50, 36, 49, 40, 19, 150]])\n",
    "    z = np.dot(x,yyy)\n",
    "    weights_used = np.dot(A,x)\n",
    "    z += - beta * np.sum(np.maximum(0, weights_used - ccc) )\n",
    "    return - z # au lieu de z cela revient à minimizer -z\n",
    "\n",
    "def MKP2(x):\n",
    "    # D = 28  # et 2 contraintes\n",
    "    yyy = np.array([1898, 440, 22507, 270, 14148, 3100, 4650, 30800, 615, 4975, 1160, 4225, 510, 11880, 479, 440, 490, 330, 110, 560, 24355, 2885, 11748, 4550, 750, 3720, 1950, 10500])\n",
    "    ccc = np.array([500, 500])\n",
    "    A = np.array([[45, 0, 85, 150, 65, 95, 30, 0, 170, 0, 40, 25, 20, 0, 0, 25, 0, 0, 25, 0, 165, 0, 85, 0, 0, 0, 0, 100],\n",
    "              [30, 20, 125, 5, 80, 25, 35, 73, 12, 15, 15, 40, 5, 10, 10, 12, 10, 9, 0, 20, 60, 40, 50, 36, 49, 40, 19, 150]])\n",
    "    z = np.dot(x,yyy)\n",
    "    weights_used = np.dot(A,x)\n",
    "    z += - beta * np.sum(np.maximum(0, weights_used - ccc) )\n",
    "    return - z # au lieu de z cela revient à minimizer -z\n",
    "\n",
    "def MKP3(x):\n",
    "    # D = 28  # et 2 contraintes\n",
    "    yyy = np.array([1898, 440, 22507, 270, 14148, 3100, 4650, 30800, 615, 4975, 1160, 4225, 510, 11880, 479, 440, 490, 330, 110, 560, 24355, 2885, 11748, 4550, 750, 3720, 1950, 10500])\n",
    "    ccc = np.array([300, 300])\n",
    "    A = np.array([[45, 0, 85, 150, 65, 95, 30, 0, 170, 0, 40, 25, 20, 0, 0, 25, 0, 0, 25, 0, 165, 0, 85, 0, 0, 0, 0, 100],\n",
    "                  [30, 20, 125, 5, 80, 25, 35, 73, 12, 15, 15, 40, 5, 10, 10, 12, 10, 9, 0, 20, 60, 40, 50, 36, 49, 40, 19, 150]])\n",
    "    z = np.dot(x,yyy)\n",
    "    weights_used = np.dot(A,x)\n",
    "    z += - beta * np.sum(np.maximum(0, weights_used - ccc) )\n",
    "    return - z # au lieu de z cela revient à minimizer -z\n",
    "\n",
    "def MKP4(x):\n",
    "    # D = 28  # et 2 contraintes\n",
    "    yyy = np.array([1898, 440, 22507, 270, 14148, 3100, 4650, 30800, 615, 4975, 1160, 4225, 510, 11880, 479, 440, 490, 330, 110, 560, 24355, 2885, 11748, 4550, 750, 3720, 1950, 10500])\n",
    "    ccc = np.array([300, 600])\n",
    "    A = np.array([[45, 0, 85, 150, 65, 95, 30, 0, 170, 0, 40, 25, 20, 0, 0, 25, 0, 0, 25, 0, 165, 0, 85, 0, 0, 0, 0, 100],\n",
    "                  [30, 20, 125, 5, 80, 25, 35, 73, 12, 15, 15, 40, 5, 10, 10, 12, 10, 9, 0, 20, 60, 40, 50, 36, 49, 40, 19, 150]])\n",
    "    z = np.dot(x,yyy)\n",
    "    weights_used = np.dot(A,x)\n",
    "    z += - beta * np.sum(np.maximum(0, weights_used - ccc) )\n",
    "    return - z # au lieu de z cela revient à minimizer -z\n",
    "\n",
    "def MKP5(x):\n",
    "    # D = 28  # et 2 contraintes\n",
    "    yyy = np.array([1898, 440, 22507, 270, 14148, 3100, 4650, 30800, 615, 4975, 1160, 4225, 510, 11880, 479, 440, 490, 330, 110, 560, 24355, 2885, 11748, 4550, 750, 3720, 1950, 10500])\n",
    "    ccc = np.array([600, 300])\n",
    "    A = np.array([[45, 0, 85, 150, 65, 95, 30, 0, 170, 0, 40, 25, 20, 0, 0, 25, 0, 0, 25, 0, 165, 0, 85, 0, 0, 0, 0, 100],\n",
    "                  [30, 20, 125, 5, 80, 25, 35, 73, 12, 15, 15, 40, 5, 10, 10, 12, 10, 9, 0, 20, 60, 40, 50, 36, 49, 40, 19, 150]])\n",
    "    z = np.dot(x,yyy)\n",
    "    weights_used = np.dot(A,x)\n",
    "    z += - beta * np.sum(np.maximum(0, weights_used - ccc) )\n",
    "    return - z # au lieu de z cela revient à minimizer -z\n",
    "\n",
    "def MKP6(x):\n",
    "    # D = 28  # et 2 contraintes\n",
    "    yyy = np.array([1898, 440, 22507, 270, 14148, 3100, 4650, 30800, 615, 4975, 1160, 4225, 510, 11880, 479, 440, 490, 330, 110, 560, 24355, 2885, 11748, 4550, 750, 3720, 1950, 10500])\n",
    "    ccc = np.array([562, 497])\n",
    "    A = np.array([[45, 0, 85, 150, 65, 95, 30, 0, 170, 0, 40, 25, 20, 0, 0, 25, 0, 0, 25, 0, 165, 0, 85, 0, 0, 0, 0, 100],\n",
    "                  [30, 20, 125, 5, 80, 25, 35, 73, 12, 15, 15, 40, 5, 10, 10, 12, 10, 9, 0, 20, 60, 40, 50, 36, 49, 40, 19, 150]])\n",
    "    z = np.dot(x,yyy)\n",
    "    weights_used = np.dot(A,x)\n",
    "    z += - beta * np.sum(np.maximum(0, weights_used - ccc) )\n",
    "    return - z # au lieu de z cela revient à minimizer -z\n",
    "\n",
    "def MKP7(x):\n",
    "    # D = 105  # et 2 contraintes\n",
    "    yyy = np.array([41850, 38261, 23800, 21697, 7074, 5587, 5560, 5500, 3450, 2391, 761, 460, 367, 24785, 47910, 30250, 107200, 4235, 9835, 9262, 15000, 6399, 6155, 10874, 37100, 27040, 4117, 32240, 1600, 4500, 70610, 6570, 15290, 23840, 16500, 7010, 16020, 8000, 31026, 2568, 2365, 4350, 1972, 4975, 29400, 7471, 2700, 3840, 22400, 3575, 13500, 1125, 11950, 12753, 10568, 15600, 20652, 13150, 2900, 1790, 4970, 5770, 8180, 2450, 7140, 12470, 6010, 16000, 11100, 11093, 4685, 2590, 11500, 5820, 2842, 5000, 3300, 2800, 5420, 900, 13300, 8450, 5300, 750, 1435, 2100, 7215, 2605, 2422, 5500, 8550, 2700, 540, 2550, 2450, 725, 445, 700, 1720, 2675, 220, 300, 405, 150, 70])\n",
    "    ccc = np.array([3000, 3000])\n",
    "    A = np.array([\n",
    "        [75, 40, 365, 95, 25, 17, 125, 20, 22, 84, 75, 50, 15, 0, 0, 12, 0, 10, 0, 50, 0, 0, 10, 0, 0, 50, 60, 150, 0, 0, 75, 0, 102, 0, 0, 40, 60, 0, 165, 0, 0, 0, 45, 0, 0, 0, 25, 0, 150, 0, 0, 0, 158, 0, 85, 95, 0, 89, 20, 0, 0, 0, 0, 0, 0, 80, 0, 110, 0, 15, 0, 60, 5, 135, 0, 0, 25, 0, 300, 35, 100, 0, 0, 25, 0, 0, 225, 25, 0, 0, 0, 0, 0, 0, 0, 5, 0, 60, 0, 100, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 10, 10, 50, 2, 5, 5, 10, 5, 6, 11, 41, 30, 5, 40, 2, 6, 100, 10, 25, 39, 30, 13, 30, 15, 60, 5, 5, 10, 5, 15, 91, 24, 10, 15, 90, 15, 60, 5, 55, 60, 50, 75, 100, 65, 15, 10, 30, 35, 50, 15, 45, 80, 40, 110, 80, 80, 36, 20, 90, 50, 25, 50, 35, 30, 60, 10, 150, 110, 70, 10, 20, 30, 104, 40, 40, 94, 150, 50, 10, 50, 50, 16, 10, 20, 50, 90, 10, 15, 39, 20, 20]])\n",
    "    z = np.dot(x,yyy)\n",
    "    weights_used = np.dot(A,x)\n",
    "    z += - beta * np.sum(np.maximum(0, weights_used - ccc) )\n",
    "    return - z # au lieu de z cela revient à minimizer -z\n",
    "\n",
    "def MKP8(x):\n",
    "    #D = 105  # et 2 contraintes\n",
    "    yyy = np.array([41850, 38261, 23800, 21697, 7074, 5587, 5560, 5500, 3450, 2391, 761, 460, 367, 24785, 47910, 30250, 107200, 4235, 9835, 9262, 15000, 6399, 6155, 10874, 37100, 27040, 4117, 32240, 1600, 4500, 70610, 6570, 15290, 23840, 16500, 7010, 16020, 8000, 31026, 2568, 2365, 4350, 1972, 4975, 29400, 7471, 2700, 3840, 22400, 3575, 13500, 1125, 11950, 12753, 10568, 15600, 20652, 13150, 2900, 1790, 4970, 5770, 8180, 2450, 7140, 12470, 6010, 16000, 11100, 11093, 4685, 2590, 11500, 5820, 2842, 5000, 3300, 2800, 5420, 900, 13300, 8450, 5300, 750, 1435, 2100, 7215, 2605, 2422, 5500, 8550, 2700, 540, 2550, 2450, 725, 445, 700, 1720, 2675, 220, 300, 405, 150, 70]) \n",
    "    ccc = np.array([500, 500])\n",
    "    A = np.array([\n",
    "        [75, 40, 365, 95, 25, 17, 125, 20, 22, 84, 75, 50, 15, 0, 0, 12, 0, 10, 0, 50, 0, 0, 10, 0, 0, 50, 60, 150, 0, 0, 75, 0, 102, 0, 0, 40, 60, 0, 165, 0, 0, 0, 45, 0, 0, 0, 25, 0, 150, 0, 0, 0, 158, 0, 85, 95, 0, 89, 20, 0, 0, 0, 0, 0, 0, 80, 0, 110, 0, 15, 0, 60, 5, 135, 0, 0, 25, 0, 300, 35, 100, 0, 0, 25, 0, 0, 225, 25, 0, 0, 0, 0, 0, 0, 0, 5, 0, 60, 0, 100, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 10, 10, 50, 2, 5, 5, 10, 5, 6, 11, 41, 30, 5, 40, 2, 6, 100, 10, 25, 39, 30, 13, 30, 15, 60, 5, 5, 10, 5, 15, 91, 24, 10, 15, 90, 15, 60, 5, 55, 60, 50, 75, 100, 65, 15, 10, 30, 35, 50, 15, 45, 80, 40, 110, 80, 80, 36, 20, 90, 50, 25, 50, 35, 30, 60, 10, 150, 110, 70, 10, 20, 30, 104, 40, 40, 94, 150, 50, 10, 50, 50, 16, 10, 20, 50, 90, 10, 15, 39, 20, 20]])\n",
    "    z = np.dot(x,yyy)\n",
    "    weights_used = np.dot(A,x)\n",
    "    z += - beta * np.sum(np.maximum(0, weights_used - ccc) )\n",
    "    return - z # au lieu de z cela revient à minimizer -z    \n",
    "\n",
    "def MKP9(x):\n",
    "    # D = 60  # et 30 contraintes\n",
    "    yyy = np.array([2, 77, 6, 67, 930, 3, 6, 270, 33, 13, 110, 21, 56, 974, 47, 734, 238, 75, 200, 51, 47, 63, 7, 6, 468, 72, 95, 82, 91, 83, 27, 13, 6, 76, 55, 72, 300, 6, 65, 39, 63, 61, 52, 85, 29, 640, 558, 53, 47, 25, 3, 6, 568, 6, 2, 780, 69, 31, 774, 22])  # 60 objets\n",
    "    ccc = np.array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4000])  # 30 contraintes\n",
    "    A = np.array([\n",
    "        [47, 774, 76, 56, 59, 22, 42, 1, 21, 760, 818, 62, 42, 36, 785, 29, 662, 49, 608, 116, 834, 57, 42, 39, 994, 690, 27, 524, 23, 96, 667, 490, 805, 46, 19, 26, 97, 71, 699, 465, 53, 26, 123, 20, 25, 450, 22, 979, 75, 96, 27, 41, 21, 81, 15, 76, 97, 646, 898, 37],\n",
    "        [73, 67, 27, 99, 35, 794, 53, 378, 234, 32, 792, 97, 64, 19, 435, 712, 837, 22, 504, 332, 13, 65, 86, 29, 894, 266, 75, 16, 86, 91, 67, 445, 118, 73, 97, 370, 88, 85, 165, 268, 758, 21, 255, 81, 5, 774, 39, 377, 18, 370, 96, 61, 57, 23, 13, 164, 908, 834, 960, 87],\n",
    "        [36, 42, 56, 96, 438, 49, 57, 16, 978, 9, 644, 584, 82, 550, 283, 340, 596, 788, 33, 350, 55, 59, 348, 66, 468, 983, 6, 33, 42, 96, 464, 175, 33, 97, 15, 22, 9, 554, 358, 587, 71, 23, 931, 931, 94, 798, 73, 873, 22, 39, 71, 864, 59, 82, 16, 444, 37, 475, 65, 5],\n",
    "        [47, 114, 26, 668, 82, 43, 55, 55, 56, 27, 716, 7, 77, 26, 950, 320, 350, 95, 714, 789, 430, 97, 590, 32, 69, 264, 19, 51, 97, 33, 571, 388, 602, 140, 15, 85, 42, 66, 778, 936, 61, 23, 449, 973, 828, 33, 53, 297, 75, 3, 54, 27, 918, 11, 620, 13, 28, 80, 79, 3],\n",
    "        [61, 720, 7, 31, 22, 82, 688, 19, 82, 654, 809, 99, 81, 97, 830, 826, 775, 72, 9, 719, 740, 860, 72, 30, 82, 112, 66, 638, 150, 13, 586, 590, 519, 2, 320, 13, 964, 754, 70, 241, 72, 12, 996, 868, 36, 91, 79, 221, 49, 690, 23, 18, 748, 408, 688, 97, 85, 777, 294, 17],\n",
    "        [698, 53, 290, 3, 62, 37, 704, 810, 42, 17, 983, 11, 45, 56, 234, 389, 712, 664, 59, 15, 22, 91, 57, 784, 75, 719, 294, 978, 75, 86, 105, 227, 760, 2, 190, 3, 71, 32, 210, 678, 41, 93, 47, 581, 37, 977, 62, 503, 32, 85, 31, 36, 30, 328, 74, 31, 56, 891, 62, 97],\n",
    "        [71, 37, 978, 93, 9, 23, 47, 71, 744, 9, 619, 32, 214, 31, 796, 103, 593, 16, 468, 700, 884, 67, 36, 3, 93, 71, 734, 504, 81, 53, 509, 114, 293, 31, 75, 59, 99, 11, 67, 306, 96, 218, 845, 303, 3, 319, 86, 724, 22, 838, 82, 5, 330, 58, 55, 66, 53, 916, 89, 56],\n",
    "        [33, 27, 13, 57, 6, 87, 21, 12, 15, 290, 206, 420, 32, 880, 854, 417, 770, 4, 12, 952, 604, 13, 96, 910, 34, 460, 76, 16, 140, 100, 876, 622, 559, 39, 640, 59, 6, 244, 232, 513, 644, 7, 813, 624, 990, 274, 808, 372, 2, 694, 804, 39, 5, 644, 914, 484, 1, 8, 43, 92],\n",
    "        [16, 36, 538, 210, 844, 520, 33, 73, 100, 284, 650, 85, 894, 2, 206, 637, 324, 318, 7, 566, 46, 818, 92, 65, 520, 721, 90, 53, 174, 43, 320, 812, 382, 16, 878, 678, 29, 92, 755, 827, 27, 218, 143, 12, 57, 480, 154, 944, 7, 730, 12, 65, 67, 39, 390, 32, 39, 318, 47, 86],\n",
    "        [45, 51, 59, 21, 53, 43, 25, 7, 42, 27, 310, 45, 72, 53, 798, 304, 354, 79, 45, 44, 52, 76, 45, 26, 27, 968, 86, 16, 62, 85, 790, 208, 390, 36, 62, 83, 93, 16, 574, 150, 99, 7, 920, 860, 12, 404, 31, 560, 37, 32, 9, 62, 7, 43, 17, 77, 73, 368, 66, 82],\n",
    "        [11, 51, 97, 26, 83, 426, 92, 39, 66, 2, 23, 93, 85, 660, 85, 774, 77, 77, 927, 868, 7, 554, 760, 104, 48, 202, 45, 75, 51, 55, 716, 752, 37, 95, 267, 91, 5, 956, 444, 529, 96, 99, 17, 99, 62, 7, 394, 580, 604, 89, 678, 476, 97, 234, 1, 608, 19, 69, 676, 51],\n",
    "        [410, 89, 414, 81, 130, 491, 6, 238, 79, 43, 5, 288, 910, 204, 948, 19, 644, 21, 295, 11, 6, 595, 904, 67, 51, 703, 430, 95, 408, 89, 11, 495, 844, 13, 417, 570, 9, 429, 16, 939, 430, 270, 49, 72, 65, 66, 338, 994, 167, 76, 47, 211, 87, 39, 1, 570, 85, 134, 967, 12],\n",
    "        [553, 63, 35, 63, 98, 402, 664, 85, 458, 834, 3, 62, 508, 7, 1, 72, 88, 45, 496, 43, 750, 222, 96, 31, 278, 184, 36, 7, 210, 55, 653, 51, 35, 37, 393, 2, 49, 884, 418, 379, 75, 338, 51, 21, 29, 95, 790, 846, 720, 71, 728, 930, 95, 1, 910, 5, 804, 5, 284, 128],\n",
    "        [423, 6, 58, 36, 37, 321, 22, 26, 16, 27, 218, 530, 93, 55, 89, 71, 828, 75, 628, 67, 66, 622, 440, 91, 73, 790, 710, 59, 83, 968, 129, 632, 170, 67, 613, 608, 43, 71, 730, 910, 36, 92, 950, 138, 23, 95, 460, 62, 189, 73, 65, 943, 62, 554, 46, 318, 13, 540, 90, 53],\n",
    "        [967, 654, 46, 69, 26, 769, 82, 89, 15, 87, 46, 59, 22, 840, 66, 35, 684, 57, 254, 230, 21, 586, 51, 19, 984, 156, 23, 748, 760, 65, 339, 892, 13, 13, 327, 65, 35, 246, 71, 178, 83, 3, 34, 624, 788, 200, 980, 882, 343, 550, 708, 542, 53, 72, 86, 51, 700, 524, 577, 948],\n",
    "        [132, 900, 72, 51, 91, 150, 22, 110, 154, 148, 99, 75, 21, 544, 110, 11, 52, 840, 201, 2, 6, 663, 22, 20, 89, 10, 93, 964, 924, 73, 501, 398, 3, 2, 279, 5, 288, 80, 91, 132, 620, 628, 57, 79, 2, 874, 36, 497, 846, 22, 350, 866, 57, 86, 83, 178, 968, 52, 399, 628],\n",
    "        [869, 26, 710, 37, 81, 89, 6, 82, 82, 56, 96, 66, 46, 13, 934, 49, 394, 72, 194, 408, 5, 541, 88, 93, 36, 398, 508, 89, 66, 16, 71, 466, 7, 95, 464, 41, 69, 130, 488, 695, 82, 39, 95, 53, 37, 200, 87, 56, 268, 71, 304, 855, 22, 564, 47, 26, 26, 370, 569, 2],\n",
    "        [494, 2, 25, 61, 674, 638, 61, 59, 62, 690, 630, 86, 198, 24, 15, 650, 75, 25, 571, 338, 268, 958, 95, 898, 56, 585, 99, 83, 21, 600, 462, 940, 96, 464, 228, 93, 72, 734, 89, 287, 174, 62, 51, 73, 42, 838, 82, 515, 232, 91, 25, 47, 12, 56, 65, 734, 70, 48, 209, 71],\n",
    "        [267, 290, 31, 844, 12, 570, 13, 69, 65, 848, 72, 780, 27, 96, 97, 17, 69, 274, 616, 36, 554, 236, 47, 7, 47, 134, 76, 62, 824, 55, 374, 471, 478, 504, 496, 754, 604, 923, 330, 22, 97, 6, 2, 16, 14, 958, 53, 480, 482, 93, 57, 641, 72, 75, 51, 96, 83, 47, 403, 32],\n",
    "        [624, 7, 96, 45, 97, 148, 91, 3, 69, 26, 22, 45, 42, 2, 75, 76, 96, 67, 688, 2, 2, 224, 83, 69, 41, 660, 81, 89, 93, 27, 214, 458, 66, 72, 384, 59, 76, 538, 15, 840, 65, 63, 77, 33, 92, 32, 35, 832, 970, 49, 13, 8, 77, 75, 51, 95, 56, 63, 578, 47],\n",
    "        [33, 62, 928, 292, 2, 340, 278, 911, 818, 770, 464, 53, 888, 55, 76, 31, 389, 40, 864, 36, 35, 37, 69, 95, 22, 648, 334, 14, 198, 42, 73, 594, 95, 32, 814, 45, 45, 515, 634, 254, 42, 29, 15, 83, 55, 176, 35, 46, 60, 296, 262, 598, 67, 644, 80, 999, 3, 727, 79, 374],\n",
    "        [19, 780, 400, 588, 37, 86, 23, 583, 518, 42, 56, 1, 108, 83, 43, 720, 570, 81, 674, 25, 96, 218, 6, 69, 107, 534, 158, 56, 5, 938, 9, 938, 274, 76, 298, 9, 518, 571, 47, 175, 63, 93, 49, 94, 42, 26, 79, 50, 718, 926, 419, 810, 23, 363, 519, 339, 86, 751, 7, 86],\n",
    "        [47, 75, 55, 554, 3, 800, 6, 13, 85, 65, 99, 45, 69, 73, 864, 95, 199, 924, 19, 948, 214, 3, 718, 56, 278, 1, 363, 86, 1, 22, 56, 114, 13, 53, 56, 19, 82, 88, 99, 543, 674, 704, 418, 670, 554, 282, 5, 67, 63, 466, 491, 49, 67, 154, 956, 911, 77, 635, 2, 49],\n",
    "        [53, 12, 79, 481, 218, 26, 624, 954, 13, 580, 130, 608, 3, 37, 91, 78, 743, 1, 950, 45, 41, 718, 36, 30, 534, 418, 452, 359, 759, 88, 29, 499, 55, 974, 93, 56, 108, 257, 93, 171, 13, 92, 63, 714, 9, 84, 890, 16, 930, 967, 748, 5, 7, 6, 327, 894, 33, 629, 448, 21],\n",
    "        [9, 19, 7, 535, 75, 3, 27, 928, 21, 7, 864, 27, 73, 61, 25, 75, 876, 16, 92, 22, 248, 11, 86, 944, 872, 996, 252, 2, 800, 334, 93, 107, 254, 441, 930, 744, 97, 177, 498, 931, 694, 800, 9, 36, 6, 539, 35, 79, 130, 860, 710, 7, 630, 475, 903, 552, 2, 45, 97, 974],\n",
    "        [17, 36, 77, 843, 328, 22, 76, 368, 39, 71, 35, 850, 96, 93, 87, 56, 972, 96, 594, 864, 344, 76, 17, 17, 576, 629, 780, 640, 56, 65, 43, 196, 520, 86, 92, 31, 6, 593, 174, 569, 89, 718, 83, 8, 790, 285, 780, 62, 378, 313, 519, 2, 85, 845, 931, 731, 42, 365, 32, 33],\n",
    "        [65, 59, 2, 671, 26, 364, 854, 526, 570, 630, 33, 654, 95, 41, 42, 27, 584, 17, 724, 59, 42, 26, 918, 6, 242, 356, 75, 644, 818, 168, 964, 12, 97, 178, 634, 21, 3, 586, 47, 382, 804, 89, 194, 21, 610, 168, 79, 96, 87, 266, 482, 46, 96, 969, 629, 128, 924, 812, 19, 2],\n",
    "        [468, 13, 9, 120, 73, 7, 92, 99, 93, 418, 224, 22, 7, 29, 57, 33, 949, 65, 92, 898, 200, 57, 12, 31, 296, 185, 272, 91, 77, 37, 734, 911, 27, 310, 59, 33, 87, 872, 73, 79, 920, 85, 59, 72, 888, 49, 12, 79, 538, 947, 462, 444, 828, 935, 518, 894, 13, 591, 22, 920],\n",
    "        [23, 93, 87, 490, 32, 63, 870, 393, 52, 23, 63, 634, 39, 83, 12, 72, 131, 69, 984, 87, 86, 99, 52, 110, 183, 704, 232, 674, 384, 47, 804, 99, 83, 81, 174, 99, 77, 708, 7, 623, 114, 1, 750, 49, 284, 492, 11, 61, 6, 449, 429, 52, 62, 482, 826, 147, 338, 911, 30, 984],\n",
    "        [35, 55, 21, 264, 5, 35, 92, 128, 65, 27, 9, 52, 66, 51, 7, 47, 670, 83, 76, 7, 79, 37, 2, 46, 480, 608, 990, 53, 47, 19, 35, 518, 71, 59, 32, 87, 96, 240, 52, 310, 86, 73, 52, 31, 83, 544, 16, 15, 21, 774, 224, 7, 83, 680, 554, 310, 96, 844, 29, 61]\n",
    "    ])\n",
    "    z = np.dot(x,yyy)\n",
    "    weights_used = np.dot(A,x)\n",
    "    z += - beta * np.sum(np.maximum(0, weights_used - ccc) )\n",
    "    return - z # au lieu de z cela revient à minimizer -z\n",
    "\n",
    "def MKP10(x):\n",
    "    # D = 60  # et 30 contraintes\n",
    "    yyy = np.array([2, 77, 6, 67, 930, 3, 6, 270, 33, 13, 110, 21, 56, 974, 47, 734, 238, 75, 200, 51, 47, 63, 7, 6, 468, 72, 95, 82, 91, 83, 27, 13, 6, 76, 55, 72, 300, 6, 65, 39, 63, 61, 52, 85, 29, 640, 558, 53, 47, 25, 3, 6, 568, 6, 2, 780, 69, 31, 774, 22])\n",
    "    ccc = np.array([10000] * 27 + [7000] + [10000] * 2) \n",
    "    A = np.array([\n",
    "        [47, 774, 76, 56, 59, 22, 42, 1, 21, 760, 818, 62, 42, 36, 785, 29, 662, 49, 608, 116, 834, 57, 42, 39, 994, 690, 27, 524, 23, 96, 667, 490, 805, 46, 19, 26, 97, 71, 699, 465, 53, 26, 123, 20, 25, 450, 22, 979, 75, 96, 27, 41, 21, 81, 15, 76, 97, 646, 898, 37],\n",
    "        [73, 67, 27, 99, 35, 794, 53, 378, 234, 32, 792, 97, 64, 19, 435, 712, 837, 22, 504, 332, 13, 65, 86, 29, 894, 266, 75, 16, 86, 91, 67, 445, 118, 73, 97, 370, 88, 85, 165, 268, 758, 21, 255, 81, 5, 774, 39, 377, 18, 370, 96, 61, 57, 23, 13, 164, 908, 834, 960, 87],\n",
    "        [36, 42, 56, 96, 438, 49, 57, 16, 978, 9, 644, 584, 82, 550, 283, 340, 596, 788, 33, 350, 55, 59, 348, 66, 468, 983, 6, 33, 42, 96, 464, 175, 33, 97, 15, 22, 9, 554, 358, 587, 71, 23, 931, 931, 94, 798, 73, 873, 22, 39, 71, 864, 59, 82, 16, 444, 37, 475, 65, 5],\n",
    "        [47, 114, 26, 668, 82, 43, 55, 55, 56, 27, 716, 7, 77, 26, 950, 320, 350, 95, 714, 789, 430, 97, 590, 32, 69, 264, 19, 51, 97, 33, 571, 388, 602, 140, 15, 85, 42, 66, 778, 936, 61, 23, 449, 973, 828, 33, 53, 297, 75, 3, 54, 27, 918, 11, 620, 13, 28, 80, 79, 3],\n",
    "        [61, 720, 7, 31, 22, 82, 688, 19, 82, 654, 809, 99, 81, 97, 830, 826, 775, 72, 9, 719, 740, 860, 72, 30, 82, 112, 66, 638, 150, 13, 586, 590, 519, 2, 320, 13, 964, 754, 70, 241, 72, 12, 996, 868, 36, 91, 79, 221, 49, 690, 23, 18, 748, 408, 688, 97, 85, 777, 294, 17],\n",
    "        [698, 53, 290, 3, 62, 37, 704, 810, 42, 17, 983, 11, 45, 56, 234, 389, 712, 664, 59, 15, 22, 91, 57, 784, 75, 719, 294, 978, 75, 86, 105, 227, 760, 2, 190, 3, 71, 32, 210, 678, 41, 93, 47, 581, 37, 977, 62, 503, 32, 85, 31, 36, 30, 328, 74, 31, 56, 891, 62, 97],\n",
    "        [71, 37, 978, 93, 9, 23, 47, 71, 744, 9, 619, 32, 214, 31, 796, 103, 593, 16, 468, 700, 884, 67, 36, 3, 93, 71, 734, 504, 81, 53, 509, 114, 293, 31, 75, 59, 99, 11, 67, 306, 96, 218, 845, 303, 3, 319, 86, 724, 22, 838, 82, 5, 330, 58, 55, 66, 53, 916, 89, 56],\n",
    "        [33, 27, 13, 57, 6, 87, 21, 12, 15, 290, 206, 420, 32, 880, 854, 417, 770, 4, 12, 952, 604, 13, 96, 910, 34, 460, 76, 16, 140, 100, 876, 622, 559, 39, 640, 59, 6, 244, 232, 513, 644, 7, 813, 624, 990, 274, 808, 372, 2, 694, 804, 39, 5, 644, 914, 484, 1, 8, 43, 92],\n",
    "        [16, 36, 538, 210, 844, 520, 33, 73, 100, 284, 650, 85, 894, 2, 206, 637, 324, 318, 7, 566, 46, 818, 92, 65, 520, 721, 90, 53, 174, 43, 320, 812, 382, 16, 878, 678, 29, 92, 755, 827, 27, 218, 143, 12, 57, 480, 154, 944, 7, 730, 12, 65, 67, 39, 390, 32, 39, 318, 47, 86],\n",
    "        [45, 51, 59, 21, 53, 43, 25, 7, 42, 27, 310, 45, 72, 53, 798, 304, 354, 79, 45, 44, 52, 76, 45, 26, 27, 968, 86, 16, 62, 85, 790, 208, 390, 36, 62, 83, 93, 16, 574, 150, 99, 7, 920, 860, 12, 404, 31, 560, 37, 32, 9, 62, 7, 43, 17, 77, 73, 368, 66, 82],\n",
    "        [11, 51, 97, 26, 83, 426, 92, 39, 66, 2, 23, 93, 85, 660, 85, 774, 77, 77, 927, 868, 7, 554, 760, 104, 48, 202, 45, 75, 51, 55, 716, 752, 37, 95, 267, 91, 5, 956, 444, 529, 96, 99, 17, 99, 62, 7, 394, 580, 604, 89, 678, 476, 97, 234, 1, 608, 19, 69, 676, 51],\n",
    "        [410, 89, 414, 81, 130, 491, 6, 238, 79, 43, 5, 288, 910, 204, 948, 19, 644, 21, 295, 11, 6, 595, 904, 67, 51, 703, 430, 95, 408, 89, 11, 495, 844, 13, 417, 570, 9, 429, 16, 939, 430, 270, 49, 72, 65, 66, 338, 994, 167, 76, 47, 211, 87, 39, 1, 570, 85, 134, 967, 12],\n",
    "        [553, 63, 35, 63, 98, 402, 664, 85, 458, 834, 3, 62, 508, 7, 1, 72, 88, 45, 496, 43, 750, 222, 96, 31, 278, 184, 36, 7, 210, 55, 653, 51, 35, 37, 393, 2, 49, 884, 418, 379, 75, 338, 51, 21, 29, 95, 790, 846, 720, 71, 728, 930, 95, 1, 910, 5, 804, 5, 284, 128],\n",
    "        [423, 6, 58, 36, 37, 321, 22, 26, 16, 27, 218, 530, 93, 55, 89, 71, 828, 75, 628, 67, 66, 622, 440, 91, 73, 790, 710, 59, 83, 968, 129, 632, 170, 67, 613, 608, 43, 71, 730, 910, 36, 92, 950, 138, 23, 95, 460, 62, 189, 73, 65, 943, 62, 554, 46, 318, 13, 540, 90, 53],\n",
    "        [967, 654, 46, 69, 26, 769, 82, 89, 15, 87, 46, 59, 22, 840, 66, 35, 684, 57, 254, 230, 21, 586, 51, 19, 984, 156, 23, 748, 760, 65, 339, 892, 13, 13, 327, 65, 35, 246, 71, 178, 83, 3, 34, 624, 788, 200, 980, 882, 343, 550, 708, 542, 53, 72, 86, 51, 700, 524, 577, 948],\n",
    "        [132, 900, 72, 51, 91, 150, 22, 110, 154, 148, 99, 75, 21, 544, 110, 11, 52, 840, 201, 2, 6, 663, 22, 20, 89, 10, 93, 964, 924, 73, 501, 398, 3, 2, 279, 5, 288, 80, 91, 132, 620, 628, 57, 79, 2, 874, 36, 497, 846, 22, 350, 866, 57, 86, 83, 178, 968, 52, 399, 628],\n",
    "        [869, 26, 710, 37, 81, 89, 6, 82, 82, 56, 96, 66, 46, 13, 934, 49, 394, 72, 194, 408, 5, 541, 88, 93, 36, 398, 508, 89, 66, 16, 71, 466, 7, 95, 464, 41, 69, 130, 488, 695, 82, 39, 95, 53, 37, 200, 87, 56, 268, 71, 304, 855, 22, 564, 47, 26, 26, 370, 569, 2],\n",
    "        [494, 2, 25, 61, 674, 638, 61, 59, 62, 690, 630, 86, 198, 24, 15, 650, 75, 25, 571, 338, 268, 958, 95, 898, 56, 585, 99, 83, 21, 600, 462, 940, 96, 464, 228, 93, 72, 734, 89, 287, 174, 62, 51, 73, 42, 838, 82, 515, 232, 91, 25, 47, 12, 56, 65, 734, 70, 48, 209, 71],\n",
    "        [267, 290, 31, 844, 12, 570, 13, 69, 65, 848, 72, 780, 27, 96, 97, 17, 69, 274, 616, 36, 554, 236, 47, 7, 47, 134, 76, 62, 824, 55, 374, 471, 478, 504, 496, 754, 604, 923, 330, 22, 97, 6, 2, 16, 14, 958, 53, 480, 482, 93, 57, 641, 72, 75, 51, 96, 83, 47, 403, 32],\n",
    "        [624, 7, 96, 45, 97, 148, 91, 3, 69, 26, 22, 45, 42, 2, 75, 76, 96, 67, 688, 2, 2, 224, 83, 69, 41, 660, 81, 89, 93, 27, 214, 458, 66, 72, 384, 59, 76, 538, 15, 840, 65, 63, 77, 33, 92, 32, 35, 832, 970, 49, 13, 8, 77, 75, 51, 95, 56, 63, 578, 47],\n",
    "        [33, 62, 928, 292, 2, 340, 278, 911, 818, 770, 464, 53, 888, 55, 76, 31, 389, 40, 864, 36, 35, 37, 69, 95, 22, 648, 334, 14, 198, 42, 73, 594, 95, 32, 814, 45, 45, 515, 634, 254, 42, 29, 15, 83, 55, 176, 35, 46, 60, 296, 262, 598, 67, 644, 80, 999, 3, 727, 79, 374],\n",
    "        [19, 780, 400, 588, 37, 86, 23, 583, 518, 42, 56, 1, 108, 83, 43, 720, 570, 81, 674, 25, 96, 218, 6, 69, 107, 534, 158, 56, 5, 938, 9, 938, 274, 76, 298, 9, 518, 571, 47, 175, 63, 93, 49, 94, 42, 26, 79, 50, 718, 926, 419, 810, 23, 363, 519, 339, 86, 751, 7, 86],\n",
    "        [47, 75, 55, 554, 3, 800, 6, 13, 85, 65, 99, 45, 69, 73, 864, 95, 199, 924, 19, 948, 214, 3, 718, 56, 278, 1, 363, 86, 1, 22, 56, 114, 13, 53, 56, 19, 82, 88, 99, 543, 674, 704, 418, 670, 554, 282, 5, 67, 63, 466, 491, 49, 67, 154, 956, 911, 77, 635, 2, 49],\n",
    "        [53, 12, 79, 481, 218, 26, 624, 954, 13, 580, 130, 608, 3, 37, 91, 78, 743, 1, 950, 45, 41, 718, 36, 30, 534, 418, 452, 359, 759, 88, 29, 499, 55, 974, 93, 56, 108, 257, 93, 171, 13, 92, 63, 714, 9, 84, 890, 16, 930, 967, 748, 5, 7, 6, 327, 894, 33, 629, 448, 21],\n",
    "        [9, 19, 7, 535, 75, 3, 27, 928, 21, 7, 864, 27, 73, 61, 25, 75, 876, 16, 92, 22, 248, 11, 86, 944, 872, 996, 252, 2, 800, 334, 93, 107, 254, 441, 930, 744, 97, 177, 498, 931, 694, 800, 9, 36, 6, 539, 35, 79, 130, 860, 710, 7, 630, 475, 903, 552, 2, 45, 97, 974],\n",
    "        [17, 36, 77, 843, 328, 22, 76, 368, 39, 71, 35, 850, 96, 93, 87, 56, 972, 96, 594, 864, 344, 76, 17, 17, 576, 629, 780, 640, 56, 65, 43, 196, 520, 86, 92, 31, 6, 593, 174, 569, 89, 718, 83, 8, 790, 285, 780, 62, 378, 313, 519, 2, 85, 845, 931, 731, 42, 365, 32, 33],\n",
    "        [65, 59, 2, 671, 26, 364, 854, 526, 570, 630, 33, 654, 95, 41, 42, 27, 584, 17, 724, 59, 42, 26, 918, 6, 242, 356, 75, 644, 818, 168, 964, 12, 97, 178, 634, 21, 3, 586, 47, 382, 804, 89, 194, 21, 610, 168, 79, 96, 87, 266, 482, 46, 96, 969, 629, 128, 924, 812, 19, 2],\n",
    "        [468, 13, 9, 120, 73, 7, 92, 99, 93, 418, 224, 22, 7, 29, 57, 33, 949, 65, 92, 898, 200, 57, 12, 31, 296, 185, 272, 91, 77, 37, 734, 911, 27, 310, 59, 33, 87, 872, 73, 79, 920, 85, 59, 72, 888, 49, 12, 79, 538, 947, 462, 444, 828, 935, 518, 894, 13, 591, 22, 920],\n",
    "        [23, 93, 87, 490, 32, 63, 870, 393, 52, 23, 63, 634, 39, 83, 12, 72, 131, 69, 984, 87, 86, 99, 52, 110, 183, 704, 232, 674, 384, 47, 804, 99, 83, 81, 174, 99, 77, 708, 7, 623, 114, 1, 750, 49, 284, 492, 11, 61, 6, 449, 429, 52, 62, 482, 826, 147, 338, 911, 30, 984],\n",
    "        [35, 55, 21, 264, 5, 35, 92, 128, 65, 27, 9, 52, 66, 51, 7, 47, 670, 83, 76, 7, 79, 37, 2, 46, 480, 608, 990, 53, 47, 19, 35, 518, 71, 59, 32, 87, 96, 240, 52, 310, 86, 73, 52, 31, 83, 544, 16, 15, 21, 774, 224, 7, 83, 680, 554, 310, 96, 844, 29, 61]\n",
    "    ])\n",
    "    z = np.dot(x,yyy)\n",
    "    weights_used = np.dot(A,x)\n",
    "    z += - beta * np.sum(np.maximum(0, weights_used - ccc) )\n",
    "    return - z # au lieu de z cela revient à minimizer -z\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "\n",
    "def create_convergence_plots(problems, convergence_data, variants, save_dir, include_variance=True):\n",
    "    from matplotlib.ticker import ScalarFormatter\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(25, 12))\n",
    "    axes = axes.flatten()\n",
    "    colors = ['blue', 'red', 'green', 'purple']\n",
    "    \n",
    "    for idx, (problem_name, (func, dim)) in enumerate(problems.items()):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        for i, variant in enumerate(variants):\n",
    "            histories = np.array(convergence_data[problem_name][variant['name']])\n",
    "            mean_curve = np.mean(histories, axis=0)\n",
    "            \n",
    "            if variant['w_type'] == 'dynamic':\n",
    "                param_str = f\"{variant['name']}\\n(c1={variant['c1']}, c2={variant['c2']}\\nw={variant['w_start']}→{variant['w_end']})\"\n",
    "            else:\n",
    "                param_str = f\"{variant['name']}\\n(c1={variant['c1']}, c2={variant['c2']}\\nw={variant['w']})\"\n",
    "            \n",
    "            ax.plot(mean_curve, \n",
    "                   color=colors[i],\n",
    "                   label=param_str if idx == 0 else \"\", \n",
    "                   linewidth=2.5)\n",
    "            \n",
    "            if include_variance:\n",
    "                std_curve = np.std(histories, axis=0)\n",
    "                ax.fill_between(range(len(mean_curve)),\n",
    "                              mean_curve - std_curve,\n",
    "                              mean_curve + std_curve,\n",
    "                              color=colors[i],\n",
    "                              alpha=0.15)\n",
    "        \n",
    "        ax.set_title(f'{problem_name} Convergence\\n(dim={dim})', \n",
    "                    fontsize=11, pad=10)\n",
    "        ax.set_xlabel('Iteration', fontsize=10)\n",
    "        ax.set_ylabel('Profit', fontsize=10)\n",
    "        ax.grid(True, linestyle='--', alpha=0.5)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=9)\n",
    "        \n",
    "        if ax.get_ylim()[1] > 1e5:\n",
    "            formatter = ScalarFormatter(useMathText=True)\n",
    "            formatter.set_scientific(True)\n",
    "            formatter.set_powerlimits((-2, 2))\n",
    "            ax.yaxis.set_major_formatter(formatter)\n",
    "    \n",
    "    legend = fig.legend(bbox_to_anchor=(1.02, 0.5), loc='center left', \n",
    "                       fontsize=10, frameon=True, fancybox=True, shadow=True)\n",
    "    legend.get_frame().set_alpha(0.9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    filename = 'convergence_with_variance.png' if include_variance else 'convergence_mean_only.png'\n",
    "    plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryPSO:\n",
    "    def __init__(self, variant_params, pop_size=30, max_iter=1000):\n",
    "        self.pop_size = pop_size\n",
    "        self.max_iter = max_iter\n",
    "        self.w_type = variant_params['w_type']\n",
    "        self.c1 = variant_params['c1']\n",
    "        self.c2 = variant_params['c2']\n",
    "        \n",
    "        if self.w_type == 'dynamic':\n",
    "            self.w_start = variant_params['w_start']\n",
    "            self.w_end = variant_params['w_end']\n",
    "        else:\n",
    "            self.w = variant_params['w']\n",
    "            \n",
    "    @staticmethod\n",
    "    def evaluate_population(func, positions):\n",
    "        \"\"\"Vectorized evaluation of multiple solutions\"\"\"\n",
    "        values = -np.array([func(pos) for pos in positions])  # Using array vectorization\n",
    "        fitness_values = np.where(values <= 1e10, values, 0)\n",
    "        return fitness_values\n",
    "\n",
    "    @staticmethod\n",
    "    def repair_batch(positions, func):\n",
    "        \"\"\"Vectorized repair mechanism\"\"\"\n",
    "        # Create a binary mask for violation of capacity\n",
    "        violations = -np.array([func(pos) for pos in positions]) > 1e10\n",
    "        repaired_positions = positions.copy()\n",
    "        \n",
    "        # For violated solutions, randomly zero out items until feasible\n",
    "        if np.any(violations):\n",
    "            # Get active indices for each solution\n",
    "            active_indices = [np.where(pos == 1)[0] for pos in positions[violations]]\n",
    "            \n",
    "            # Create a mask for random removal\n",
    "            random_masks = [np.random.permutation(len(idx)) for idx in active_indices]\n",
    "            \n",
    "            # Apply repairs\n",
    "            for i, pos_idx in enumerate(np.where(violations)[0]):\n",
    "                temp_pos = repaired_positions[pos_idx].copy()\n",
    "                indices_to_try = active_indices[i][random_masks[i]]\n",
    "                \n",
    "                for idx in indices_to_try:\n",
    "                    temp_pos[idx] = 0\n",
    "                    if -BinaryPSO.evaluate_population(func, [temp_pos])[0] <= 1e10:\n",
    "                        repaired_positions[pos_idx] = temp_pos\n",
    "                        break\n",
    "        \n",
    "        return repaired_positions\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -6, 6)))\n",
    "\n",
    "    def initialize_population(self, dimension):\n",
    "        positions = np.random.randint(0, 2, (self.pop_size, dimension))\n",
    "        velocities = np.random.uniform(-4, 4, (self.pop_size, dimension))\n",
    "        return positions, velocities\n",
    "\n",
    "    def repair_solution(self, position, func):\n",
    "        if -BinaryPSO.evaluate_population(func, [position])[0] > 1e10:\n",
    "            indices = np.where(position == 1)[0]\n",
    "            np.random.shuffle(indices)\n",
    "            for idx in indices:\n",
    "                position[idx] = 0\n",
    "                if -BinaryPSO.evaluate_population(func, [position])[0] <= 1e10:\n",
    "                    break\n",
    "        return position\n",
    "\n",
    "    def optimize(self, func, dimension):\n",
    "        # Initialize\n",
    "        positions, velocities = self.initialize_population(dimension)\n",
    "        positions = np.array([self.repair_solution(pos.copy(), func) for pos in positions])\n",
    "        \n",
    "        # Initialize tracking arrays\n",
    "        fitness = BinaryPSO.evaluate_population(func, positions)\n",
    "        personal_best_positions = positions.copy()\n",
    "        personal_best_fitness = fitness.copy()\n",
    "        \n",
    "        # Global best\n",
    "        global_best_idx = np.argmax(personal_best_fitness)\n",
    "        global_best_position = personal_best_positions[global_best_idx].copy()\n",
    "        global_best_fitness = personal_best_fitness[global_best_idx]\n",
    "        \n",
    "        # History\n",
    "        fitness_history = [global_best_fitness]\n",
    "        \n",
    "        # Pre-allocate random arrays\n",
    "        all_r1 = np.random.random((self.max_iter, self.pop_size, dimension))\n",
    "        all_r2 = np.random.random((self.max_iter, self.pop_size, dimension))\n",
    "        pos_rand = np.random.random((self.max_iter, self.pop_size, dimension))\n",
    "\n",
    "        # Main loop\n",
    "        for t in range(self.max_iter):\n",
    "            # Update inertia weight\n",
    "            if self.w_type == 'dynamic':\n",
    "                w = self.w_start - (self.w_start - self.w_end) * t / self.max_iter\n",
    "            else:\n",
    "                w = self.w\n",
    "            \n",
    "            # Update velocities\n",
    "            velocities = (w * velocities + \n",
    "                        self.c1 * all_r1[t] * (personal_best_positions - positions) +\n",
    "                        self.c2 * all_r2[t] * (global_best_position - positions))\n",
    "            velocities = np.clip(velocities, -4, 4)\n",
    "            \n",
    "            # Update positions\n",
    "            positions = (pos_rand[t] < self.sigmoid(velocities)).astype(int)\n",
    "            \n",
    "            # Repair invalid solutions\n",
    "            positions = BinaryPSO.repair_batch(positions, func)\n",
    "            \n",
    "            # Evaluate new positions\n",
    "            fitness = BinaryPSO.evaluate_population(func, positions)\n",
    "            \n",
    "            # Update personal bests\n",
    "            improved = fitness > personal_best_fitness\n",
    "            personal_best_positions[improved] = positions[improved].copy()\n",
    "            personal_best_fitness[improved] = fitness[improved]\n",
    "            \n",
    "            # Update global best\n",
    "            current_best = np.argmax(fitness)\n",
    "            if fitness[current_best] > global_best_fitness:\n",
    "                global_best_position = positions[current_best].copy()\n",
    "                global_best_fitness = fitness[current_best]\n",
    "            \n",
    "            fitness_history.append(global_best_fitness)\n",
    "            \n",
    "        return global_best_fitness, fitness_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_variant_test(args):\n",
    "    variant, func, dim, n_runs, max_iter = args\n",
    "    bpso = BinaryPSO(variant, max_iter=max_iter)\n",
    "    results = []\n",
    "    histories = []\n",
    "    \n",
    "    for _ in range(n_runs):\n",
    "        fitness, history = bpso.optimize(func, dim)\n",
    "        results.append(fitness)\n",
    "        histories.append(history)\n",
    "        \n",
    "    return np.array(results), histories\n",
    "\n",
    "def test_variants(variants, n_runs=30, max_iter=1000):\n",
    "    problems = {\n",
    "        'MKP1': (MKP1, 28),\n",
    "        'MKP2': (MKP2, 28),\n",
    "        'MKP3': (MKP3, 28),\n",
    "        'MKP4': (MKP4, 28),\n",
    "        'MKP5': (MKP5, 28),\n",
    "        'MKP6': (MKP6, 28),\n",
    "        'MKP7': (MKP7, 105),\n",
    "        'MKP8': (MKP8, 105),\n",
    "        'MKP9': (MKP9, 60),\n",
    "        'MKP10': (MKP10, 60)\n",
    "    }\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    save_dir = f\"bpso_results_{timestamp}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    all_results = {'Méthode': 'BPSO', 'Résultats': {}}\n",
    "    convergence_data = {problem: {v['name']: [] for v in variants} for problem in problems}\n",
    "    \n",
    "    for problem_name, (func, dim) in problems.items():\n",
    "        print(f\"\\nTesting {problem_name}\")\n",
    "        problem_results = {}\n",
    "        \n",
    "        for variant in variants:\n",
    "            print(f\"\\nTesting {variant['name']}\")\n",
    "            \n",
    "            args = (variant, func, dim, n_runs, max_iter)\n",
    "            fitnesses, histories = run_variant_test(args)\n",
    "            \n",
    "            problem_results[variant['name']] = {\n",
    "                'Meilleure': float(np.max(fitnesses)),\n",
    "                'Moyenne': float(np.mean(fitnesses)),\n",
    "                'Ecart type': float(np.std(fitnesses))\n",
    "            }\n",
    "            \n",
    "            convergence_data[problem_name][variant['name']].extend(histories)\n",
    "            \n",
    "        all_results['Résultats'][problem_name] = problem_results\n",
    "    \n",
    "    create_convergence_plots(problems, convergence_data, variants, save_dir, include_variance=True)\n",
    "    create_convergence_plots(problems, convergence_data, variants, save_dir, include_variance=False)\n",
    "    \n",
    "    with open(os.path.join(save_dir, \"resultats.json\"), 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_results, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    return all_results, save_dir\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    variants = [\n",
    "        {'name': 'BPSO1', 'w_type': 'dynamic', 'w_start': 0.9, 'w_end': 0.4, 'c1': 6.0, 'c2': 6.0},\n",
    "        {'name': 'BPSO2', 'w_type': 'static', 'w': 0.8, 'c1': 8.0, 'c2': 4.0},\n",
    "        {'name': 'BPSO3', 'w_type': 'static', 'w': 0.7, 'c1': 3.0, 'c2': 7.0},\n",
    "        {'name': 'BPSO4', 'w_type': 'dynamic', 'w_start': 0.9, 'w_end': 0.4, 'c1': 9.0, 'c2': 11.0}\n",
    "    ]\n",
    "    \n",
    "    print(\"Starting test run with reduced parameters...\")\n",
    "    results, save_dir = test_variants(variants, n_runs=30, max_iter=1000)\n",
    "    print(f\"\\nTest results saved in: {save_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
